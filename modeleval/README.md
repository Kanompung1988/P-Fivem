# üéØ Model Benchmark System

‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö AI Models ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Seoulholic Clinic Chatbot

## üìã Overview

‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á AI models ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

### üéØ Models ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (7 models)

| Model                   | Provider | Cost (per 1M tokens) | Thai Support      | ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡πÄ‡∏î‡πà‡∏ô                   |
| ----------------------- | -------- | -------------------- | ----------------- | --------------------------- |
| **Gemini-1.5-Flash** ‚≠ê | Google   | **$0.07/$0.30**      | üáπüá≠ **Excellent**  | **‡∏ñ‡∏π‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î + ‡πÄ‡∏£‡πá‡∏ß**        |
| GPT-4o-mini             | OpenAI   | $0.15/$0.60          | ‚úÖ Good           | Reliable, Fast              |
| DeepSeek v3             | DeepSeek | $0.27/$1.10          | ‚úÖ Good           | GPT-4o-level ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å        |
| Typhoon v2.5 30B        | Typhoon  | $0.30/$0.30          | üáπüá≠ **Specialist** | Thai-first, Local context   |
| Groq Llama 3.1 70B      | Groq     | $0.59/$0.79          | ‚úÖ Good           | **‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î** (500+ tok/s) |
| Gemini-1.5-Pro          | Google   | $1.25/$5.00          | üáπüá≠ **Excellent**  | 1M+ context window          |
| GPT-4o                  | OpenAI   | $2.50/$10.00         | ‚úÖ Good           | Best reasoning              |

## üìä Test Dataset

‡πÉ‡∏ä‡πâ **real data** ‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ:

- **test_dataset_large.json**: 1,000 test cases
  - Categories: services_pricing, complex, promotions, comparison, clinic_info, edge_case
  - Difficulty levels: easy (638), medium (228), hard (134)
  - Expected keywords ‡πÅ‡∏•‡∏∞ should_not_contain

- **customer_qa_final.json**: ~24,000 Q&A pairs
  - ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô ground truth reference

## üöÄ Quick Start

### 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

```bash
pip install openai python-dotenv
```

### 2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Keys

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `.env` ‡∏ó‡∏µ‡πà root ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ:

```bash
# OpenAI
OPGoogle Gemini (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ - ‡∏ñ‡∏π‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!)
GOOGLE_API_KEY=...

# Typhoon (Optional - Thai specialist)
TYPHOON_API_KEY=...

# DeepSeek (Optional - cost-effective)
DEEPSEEK_API_KEY=...

# Groq (Optional - fastest)
GROQ_API_KEY=...
```

**üí° Tip**: ‡∏£‡∏±‡∏ö Google API Key ‡∏ü‡∏£‡∏µ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà https://ai.google.dev/roq (Optional)
GROQ_API_KEY=...

````

### 3. ‡∏£‡∏±‡∏ô Benchmark

#### ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å models ‡∏î‡πâ‡∏ß‡∏¢ test cases ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ô‡πâ‡∏≠‡∏¢ (10 tests):

```bash
cd modeleval
python benchmark_real_data.py --max-tests 10
# ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Gemini vs GPT-4o-mini
python benchmark_real_data.py --models Gemini-1.5-Flash GPT-4o-mini --max-tests 20

# ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Thai specialists
python benchmark_real_data.py --models Gemini-1.5-Flash

#### ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏≤‡∏á models:

```bash
python benchmark_real_data.py --models GPT-4o-mini Typhoon-v2.5-30B --max-tests 20
````

#### ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (1,000 test cases):

```bash
python benchmark_real_data.py
```

‚ö†Ô∏è **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô (30-60 ‡∏ô‡∏≤‡∏ó‡∏µ) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢ API

### 4. ‡∏î‡∏π Results

‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô `modeleval/results/`:

```
results/
‚îú‚îÄ‚îÄ benchmark_results_20260219_143022.json   # ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏∏‡∏Å test case
‚îî‚îÄ‚îÄ benchmark_summary_20260219_143022.json   # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
```

### 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á Report

```bash
python report_generator.py results/benchmark_summary_20260219_143022.json
```

‡πÑ‡∏î‡πâ‡πÑ‡∏ü‡∏•‡πå markdown report ‡∏û‡∏£‡πâ‡∏≠‡∏° analysis ‡πÅ‡∏•‡∏∞ recommendations

## üìà Evaluation Metrics

### 1. **Quality Score** (0-1)

- Keyword matching: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏°‡∏µ expected keywords
- Violation penalty: ‡∏´‡∏±‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ (should_not_contain)
- Length score: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

### 2. **Latency** (milliseconds)

- ‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡πÅ‡∏ö‡∏ö end-to-end ‡∏£‡∏ß‡∏° network latency

### 3. **Cost** (USD)

- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å tokens ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ √ó ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢

### 4. **Thai Ratio**

- ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö

## üìÅ File Structure

```
modeleval/
‚îú‚îÄ‚îÄ models_config.py           # ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ models ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
‚îú‚îÄ‚îÄ test_dataset.py            # Synthetic test dataset (backup)
‚îú‚îÄ‚îÄ benchmark.py               # Benchmark runner (basic)
‚îú‚îÄ‚îÄ benchmark_real_data.py     # Benchmark runner (real data) ‚≠ê
‚îú‚îÄ‚îÄ report_generator.py        # ‡∏™‡∏£‡πâ‡∏≤‡∏á markdown report
‚îú‚îÄ‚îÄ README.md                  # ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ
‚îî‚îÄ‚îÄ results/                   # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    ‚îú‚îÄ‚îÄ benchmark_results_*.json
    ‚îú‚îÄ‚îÄ benchmark_summary_*.json
    ‚îî‚îÄ‚îÄ benchmark_report_*.md
```

## üí° Use Cases

### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Development

```bash
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏£‡πá‡∏ß‡πÜ ‡∏Å‡∏±‡∏ö 5 test cases
python benchmark_real_data.py --max-tests 5 --models GPT-4o-mini
```

### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production Decision

```bash
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö 100 test cases
python benchmark_real_data.py --max-tests 100

# ‡∏™‡∏£‡πâ‡∏≤‡∏á report
python report_generator.py results/benchmark_summary_*.json
```

### ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö 2 models

```bash
python benchmark_real_data.py --models GPT-4o-mini Typhoon-v2.5-30B --max-tests 50
```

## üîç Example Output

```
üöÄ Running benchmark for: GPT-4o-mini
   Provider: OpenAI
   Model ID: gpt-4o-mini
   Test cases: 10
================================================================================

[1/10] Testing: ‡∏£‡∏≤‡∏Ñ‡∏≤ Diode Laser ‡∏ó‡∏µ‡πà Seoulholic Clinic ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?...
   ‚úÖ Success | Latency: 892ms | Quality: 85% | Tokens: 245

[2/10] Testing: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ü‡∏¥‡∏•‡πÄ‡∏•‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡∏°‡∏µ‡∏Å‡∏µ‡πà‡πÅ‡∏ö‡∏ö...
   ‚úÖ Success | Latency: 1024ms | Quality: 90% | Tokens: 312

================================================================================
üìä Summary for GPT-4o-mini:
   Success Rate: 10/10
   Avg Latency: 956ms
   Avg Quality Score: 87%
   Avg Keyword Score: 82%
   Thai Content Ratio: 95%
   Total Cost: $0.0142
   Cost per 1k queries: $1.42
================================================================================
```

## üéØ Recommendations

### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production

1. **Best Quality**: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model ‡∏ó‡∏µ‡πà quality score ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
2. **Cost-Effective**: ‡∏î‡∏π cost per 1k queries
3. **Low Latency**: ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö real-time chat
4. **Thai Specialist**: Typhoon ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Thai-first applications

### Strategy

1. ‡πÉ‡∏ä‡πâ model ‡∏´‡∏•‡∏±‡∏Å 1 ‡∏ï‡∏±‡∏ß ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
2. ‡∏°‡∏µ fallback model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ rate limit
3. Route ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢ ‚Üí model ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤
4. Monitor metrics ‡πÉ‡∏ô production

## üêõ Troubleshooting

### ‚ùå API Key Error

```
‚ö†Ô∏è  API key not found for GPT-4o-mini (env: OPENAI_API_KEY)
```

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå `.env` ‡∏°‡∏µ API key ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

### ‚ùå Rate Limit

```
‚ùå Error: Rate limit exceeded
```

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç**:

- ‡πÄ‡∏û‡∏¥‡πà‡∏° delay ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á requests (‡πÅ‡∏Å‡πâ‡πÉ‡∏ô code: `time.sleep(1.0)`)
- ‡∏•‡∏î `--max-tests`
- Upgrade API plan

### ‚ùå Test Dataset Not Found

```
‚ö†Ô∏è  Test dataset not found at /path/to/test_dataset_large.json
```

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà `../data/test_dataset_large.json`

## üèÜ Benchmark Results (Latest)

**Date:** February 19, 2026  
**Tests:** 500 total (100 per model √ó 5 models)

### Top Performers

| Model | Quality | Latency | Cost/1k | Error Rate | Status |
|-------|---------|---------|---------|------------|--------|
| ü•á **Typhoon-v2.5-30B** | **80%** | 6.7s | $0.15 | 12% | ‚úÖ Recommended |
| ü•á **DeepSeek-v3** | **80%** | 4.3s | $0.24 | 12% | ‚úÖ Recommended |
| ü•â Groq-Llama-3.3-70B | 73% | 2.0s | $0.29 | 30% | ‚ö†Ô∏è Unreliable |
| GPT-4o-mini | 68% | 2.5s | $0.09 | 18% | ‚úÖ Cost-effective |
| GPT-4o | 65% | 2.2s | $1.57 | 23% | ‚ùå Expensive |

**Recommendation:** Use **Typhoon-v2.5-30B** (Thai-optimized) or **DeepSeek-v3** (faster, balanced)

---

## üìö Complete Documentation

We provide comprehensive handoff documentation for deployment:

### Core Documents

1. **[MODEL_HANDOFF.md](MODEL_HANDOFF.md)** - Complete model selection report
   - Benchmark results summary
   - Error analysis findings
   - Model comparison and recommendations
   - Deliverables checklist

2. **[INTEGRATION_GUIDE.md](INTEGRATION_GUIDE.md)** - Technical integration guide
   - Step-by-step code examples
   - API configuration
   - Testing procedures
   - Monitoring setup

3. **[RECOMMENDATIONS.md](RECOMMENDATIONS.md)** - Best practices
   - Deployment strategies
   - Optimization tactics
   - Quality improvement plan
   - Cost reduction strategies

### Additional Tools

4. **[optimized_prompts.py](optimized_prompts.py)** - 7 prompt versions
   - Professional, Friendly, Concise, Safety-focused, Sales-oriented
   - Few-shot examples, JSON structured output
   
5. **[error_analysis.py](error_analysis.py)** - Error analysis tool
   - Identifies low-quality responses
   - Patterns and recommendations
   - Exports CSV for review

6. **[generate_human_eval.py](generate_human_eval.py)** - Human evaluation templates
   - Sampling and evaluation forms
   - Side-by-side model comparison

### Generated Reports

- `results/benchmark_report_20260219_125736.md` - Full benchmark report
- `results/low_quality_responses_for_review.csv` - 95 problematic cases
- `results/human_evaluation_template.csv` - 50 samples for evaluation
- `results/model_comparison_template.csv` - Typhoon vs DeepSeek comparison

---

## üìù Project Status

### ‚úÖ Completed Tasks

1. ‚úÖ Evaluated 5 AI models with 100 tests each (500 total)
2. ‚úÖ Conducted comprehensive error analysis
3. ‚úÖ Created 7 optimized prompt templates
4. ‚úÖ Generated human evaluation templates
5. ‚úÖ Wrote complete handoff documentation
6. ‚úÖ Prepared integration guides and recommendations

### üéØ Ready for Deployment

All deliverables prepared and ready to hand off to deployment team:
- Model selection complete (Typhoon or DeepSeek recommended)
- Integration code examples provided
- Monitoring and optimization strategies documented
- Human evaluation templates ready for validation

## ü§ù Contributing

‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° model ‡πÉ‡∏´‡∏°‡πà:

1. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô `models_config.py`
2. ‡πÄ‡∏û‡∏¥‡πà‡∏° API key ‡πÉ‡∏ô `.env`
3. ‡∏£‡∏±‡∏ô benchmark

## üìÑ License

MIT

---

**Created for Seoulholic Clinic AI Chatbot Project**
