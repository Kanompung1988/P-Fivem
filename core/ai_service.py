import os
import re
import sys
import hashlib
import time
from pathlib import Path
from typing import List, Dict, Any, Optional, Iterable, Union
import numpy as np
from dotenv import load_dotenv

# Load env variables (Ensure this is called if used outside of main app)
env_path = Path(__file__).resolve().parents[1] / ".env"
if env_path.exists():
    load_dotenv(dotenv_path=env_path)
else:
    load_dotenv()


def _get_env(name: str, default: Optional[str] = None) -> Optional[str]:
    value = os.getenv(name)
    if value is None or value.strip() == "":
        return default
    return value


class AIService:
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(AIService, cls).__new__(cls)
            cls._instance.initialized = False
        return cls._instance

    def __init__(self):
        if self.initialized:
            return
        
        # à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰ Typhoon à¸à¹ˆà¸­à¸™ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¹ˆà¸­à¸¢à¹ƒà¸Šà¹‰ OpenAI
        typhoon_key = _get_env("TYPHOON_API_KEY")
        if typhoon_key:
            self.api_key = typhoon_key
            self.base_url = "https://api.opentyphoon.ai/v1"
            self.model_name = _get_env("TYPHOON_MODEL", "typhoon-v2.5-30b-a3b-instruct")
            print("[AI] Using Typhoon AI")
        else:
            self.api_key = _get_env("OPENAI_API_KEY")
            self.base_url = _get_env("OPENAI_BASE_URL")
            self.model_name = _get_env("OPENAI_MODEL", "gpt-4o-mini")
            print("[AI] Using OpenAI")
            
        self.client = self._create_openai_client()
        self.knowledge_base = []
        
        # In-memory cache for fast response (Senior AI Engineer optimization)
        self.response_cache = {}  # {query_hash: {"response": str, "timestamp": float}}
        self.cache_ttl = 3600  # 1 hour
        self.cache_hits = 0
        self.cache_misses = 0
        
        # Load knowledge immediately
        self.reload_knowledge_base()
        
        self.initialized = True

    def _create_openai_client(self):
        """Create an OpenAI client if configuration exists; otherwise return None."""
        if not self.api_key:
            return None

        try:
            from openai import OpenAI
            if self.base_url:
                return OpenAI(api_key=self.api_key, base_url=self.base_url)
            return OpenAI(api_key=self.api_key)
        except Exception as e:
            print(f"Error creating OpenAI client: {e}")
            return None
    
    def _get_cache_key(self, text: str) -> str:
        """Generate cache key from text using hash"""
        return hashlib.md5(text.lower().strip().encode('utf-8')).hexdigest()
    
    def _clean_markdown(self, text: str) -> str:
        """AGGRESSIVE: Remove ALL markdown formatting from response"""
        import re
        
        # Remove bold **text** and __text__
        text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
        text = re.sub(r'__(.+?)__', r'\1', text)
        
        # Remove italic *text* and _text_
        text = re.sub(r'(?<!\*)\*(?!\*)(.+?)(?<!\*)\*(?!\*)', r'\1', text)
        text = re.sub(r'(?<!_)_(?!_)(.+?)(?<!_)_(?!_)', r'\1', text)
        
        # Remove headers ### ## #
        text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
        
        # Remove links [text](url) -> text
        text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
        
        # Remove code blocks ```code```
        text = re.sub(r'```[\w]*\n?(.+?)```', r'\1', text, flags=re.DOTALL)
        text = re.sub(r'`(.+?)`', r'\1', text)
        
        # Remove horizontal rules
        text = re.sub(r'^(-{3,}|\*{3,}|_{3,})$', '', text, flags=re.MULTILINE)
        
        # Clean up multiple newlines
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        return text.strip()
    
    def _get_cached_response(self, query: str) -> Optional[str]:
        """Get cached response if exists and not expired"""
        cache_key = self._get_cache_key(query)
        if cache_key in self.response_cache:
            cached = self.response_cache[cache_key]
            if time.time() - cached["timestamp"] < self.cache_ttl:
                self.cache_hits += 1
                return cached["response"]
            else:
                # Expired - remove
                del self.response_cache[cache_key]
        self.cache_misses += 1
        return None
    
    def _set_cached_response(self, query: str, response: str):
        """Cache the response"""
        cache_key = self._get_cache_key(query)
        self.response_cache[cache_key] = {
            "response": response,
            "timestamp": time.time()
        }
        # Limit cache size to 1000 entries
        if len(self.response_cache) > 1000:
            # Remove oldest entries
            sorted_keys = sorted(self.response_cache.keys(), 
                               key=lambda k: self.response_cache[k]["timestamp"])
            for key in sorted_keys[:100]:
                del self.response_cache[key]
    
    def _expand_query(self, query: str) -> str:
        """Expand query with synonyms and related terms for better RAG matching"""
        # Keyword expansion mapping (Thai clinic terms)
        expansions = {
            'mts': 'MTS PDRN à¹€à¸‚à¹‡à¸¡ à¸œà¸´à¸§',
            'pdrn': 'PDRN MTS à¸Ÿà¸·à¹‰à¸™à¸Ÿà¸¹ à¸„à¸­à¸¥à¸¥à¸²à¹€à¸ˆà¸™',
            'à¸Ÿà¸´à¸¥à¹€à¸¥à¸­à¸£à¹Œ': 'Filler à¸Ÿà¸´à¸¥à¹€à¸¥à¸­à¸£à¹Œ à¹€à¸ªà¸£à¸´à¸¡',
            'filler': 'Filler à¸Ÿà¸´à¸¥à¹€à¸¥à¸­à¸£à¹Œ à¹€à¸ªà¸£à¸´à¸¡',
            'à¸›à¸²à¸': 'Lip à¸£à¸´à¸¡à¸à¸µà¸›à¸²à¸ à¸›à¸²à¸',
            'lip': 'Lip à¸›à¸²à¸ à¸£à¸´à¸¡à¸à¸µà¸›à¸²à¸',
            'à¹‚à¸›à¸£': 'à¹‚à¸›à¸£à¹‚à¸¡à¸Šà¸±à¹ˆà¸™ promotion à¸¥à¸”à¸£à¸²à¸„à¸²',
            'promotion': 'à¹‚à¸›à¸£à¹‚à¸¡à¸Šà¸±à¹ˆà¸™ promotion à¸¥à¸”',
            'à¸„à¸¥à¸´à¸™à¸´à¸': 'à¸„à¸¥à¸´à¸™à¸´à¸ clinic à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆ à¸ªà¸–à¸²à¸™à¸—à¸µà¹ˆ',
            'clinic': 'à¸„à¸¥à¸´à¸™à¸´à¸ clinic à¸—à¸µà¹ˆà¸•à¸±à¹‰à¸‡',
            'à¸ˆà¸­à¸‡': 'à¸ˆà¸­à¸‡à¸„à¸´à¸§ à¸™à¸±à¸”à¸«à¸¡à¸²à¸¢ à¸•à¸´à¸”à¸•à¹ˆà¸­',
            'sculptra': 'Sculptra à¸«à¸™à¹‰à¸²à¹€à¸”à¹‡à¸ à¸„à¸­à¸¥à¸¥à¸²à¹€à¸ˆà¸™',
            'à¸«à¸™à¹‰à¸²à¹€à¸”à¹‡à¸': 'Sculptra à¸«à¸™à¹‰à¸²à¹€à¸”à¹‡à¸ à¸Ÿà¸¹',
            'à¸£à¸´à¹‰à¸§à¸£à¸­à¸¢': 'à¸£à¸´à¹‰à¸§à¸£à¸­à¸¢ wrinkle anti-aging',
            'à¸œà¸´à¸§à¹à¸«à¹‰à¸‡': 'à¸œà¸´à¸§à¹à¸«à¹‰à¸‡ dry à¸Šà¸¸à¹ˆà¸¡à¸Šà¸·à¹‰à¸™',
        }
        
        query_lower = query.lower()
        expanded = query
        
        for keyword, expansion in expansions.items():
            if keyword in query_lower:
                expanded += f" {expansion}"
        
        return expanded

    def _get_embedding(self, text: str) -> List[float]:
        """Get embedding for text using OpenAI API (Typhoon à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š embeddings)"""
        if not self.client:
            return []
        
        # Typhoon à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ embedding API - à¸‚à¹‰à¸²à¸¡
        if "typhoon" in self.model_name.lower():
            return []
            
        try:
            # Normalize text (better for caching)
            text = text.replace("\n", " ").strip()
            return self.client.embeddings.create(input=[text], model="text-embedding-3-small").data[0].embedding
        except Exception as e:
            # Suppress embedding errors for Typhoon
            if "typhoon" not in self.model_name.lower():
                print(f"Embedding error: {e}")
            return []

    def reload_knowledge_base(self):
        """Reloads the knowledge base from disk and updates embeddings."""
        print("Reloading Knowledge Base...")
        self.knowledge_base = self._load_knowledge_base_from_files()
        print(f"Knowledge Base Loaded: {len(self.knowledge_base)} documents.")

    def _load_knowledge_base_from_files(self) -> List[Dict[str, Any]]:
        """Download data from files /data/text"""
        knowledge = []
        # Path to data/text relative to this file core/ai_service.py -> ../data/text
        data_path = Path(__file__).resolve().parents[1] / "data" / "text"
        
        if not data_path.exists():
            return knowledge
        
        for txt_file in data_path.glob("*.txt"):
            try:
                with open(txt_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    if not content.strip():
                        continue

                    doc = {
                        "source": txt_file.stem,
                        "content": content,
                        "embedding": []
                    }
                    
                    # Compute embedding
                    if self.client:
                        doc["embedding"] = self._get_embedding(content)
                        
                    knowledge.append(doc)
            except Exception as e:
                print(f"Error reading file {txt_file}: {e}")
                continue
        
        return knowledge

    def rewrite_query(self, user_text: str, history: List[Dict[str, str]]) -> str:
        """
        Rewrite user query based on conversation history to make it standalone.
        Senior AI Engineer optimization: Better context extraction
        """
        # Quick return for simple queries
        if not history or not self.client or len(user_text) < 10:
            return user_text
            
        # Extract last few turns (last 4 pairs) for better context
        conversation_str = ""
        for msg in history[-8:]: 
            role = "User" if msg["role"] == "user" else "Assistant"
            content = msg["content"]
            # Skip system prompts or empty content
            if msg["role"] == "system" or not content:
                continue
            # Truncate long messages
            if len(content) > 200:
                content = content[:200] + "..."
            conversation_str += f"{role}: {content}\n"
            
        if not conversation_str.strip():
            return user_text
            
        prompt = f"""Conversation History:
{conversation_str}
User's Follow-up Question: {user_text}

Task: Rephrase the user's follow-up question to be a standalone question that includes necessary context from the history. If the user's question is already standalone or changes the topic completely, return it exactly as is. Do not answer the question.

Standalone Question:"""

        try:
            # Use gpt-3.5-turbo or gpt-4o-mini for speed here
            resp = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=150
            )
            rewritten = resp.choices[0].message.content.strip()
            # If model returns empty or quote, fallback
            if not rewritten:
                return user_text
            print(f"Rewritten Query: '{user_text}' -> '{rewritten}'")
            return rewritten
        except Exception as e:
            print(f"Rewrite error: {e}")
            return user_text

    def find_relevant_info(self, user_text: str, history: Optional[List[Dict[str, str]]] = None) -> str:
        """Find relevant info using Vector Similarity Search with Contextual Rewriting"""
        if not self.knowledge_base:
            return ""
            
        search_query = user_text
        
        # Rewrite query if history is provided
        if history:
            search_query = self.rewrite_query(user_text, history)
            
        # Check if we have embeddings
        has_embeddings = any(len(doc["embedding"]) > 0 for doc in self.knowledge_base)
        
        if not self.client or not has_embeddings:
            # Fallback to simple keyword match (use original text mostly, or rewritten if simple)
            # For keyword match, sometimes rewritten query is better, sometimes worse.
            # Let's use search_query generally.
            query_lower = search_query.lower()
            found = []
            for doc in self.knowledge_base:
                if doc["source"].lower() in query_lower:
                    found.append(f"--- {doc['source']} ---\n{doc['content']}")
            return "\n\n".join(found[:2])
        
        try:
            # 1. Get query embedding
            query_embedding = self._get_embedding(search_query)
            if not query_embedding:
                return ""
                
            # 2. Calculate Cosine Similarity
            results = []
            query_vec = np.array(query_embedding)
            query_norm = np.linalg.norm(query_vec)
            
            if query_norm == 0:
                return ""
                
            for doc in self.knowledge_base:
                if not doc["embedding"]: continue
                
                doc_vec = np.array(doc["embedding"])
                doc_norm = np.linalg.norm(doc_vec)
                
                if doc_norm == 0:
                    score = 0
                else:
                    score = np.dot(query_vec, doc_vec) / (query_norm * doc_norm)
                    
                results.append((score, doc))
                
            # Sort by score descending
            results.sort(key=lambda x: x[0], reverse=True)
            
            # 3. Filter and Format Results
            relevant_docs = []
            
            # Special Logic: Promo check (Use original user_text for simple keyword check as it is more direct)
            promo_keywords = ["à¹‚à¸›à¸£", "promotion", "à¸¥à¸”", "discount", "à¸£à¸²à¸„à¸²", "price", "à¹‚à¸›à¸£à¹‚à¸¡à¸Šà¸±à¹ˆà¸™"]
            is_asking_promo = any(k in user_text.lower() for k in promo_keywords)
            
            fb_promo = next((doc for doc in self.knowledge_base if doc["source"] == "FacebookPromotions"), None)
            
            if is_asking_promo and fb_promo:
                 relevant_docs.append(f"\n--- à¹‚à¸›à¸£à¹‚à¸¡à¸Šà¸±à¹ˆà¸™à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸ˆà¸²à¸ Facebook ---\n{fb_promo['content']}")
            
            count = 0
            for score, doc in results:
                if count >= 2: break  # OPTIMIZED: Reduced from 5 to 2 documents for more focused responses
                if score < 0.20: break  # OPTIMIZED: Increased from 0.15 to 0.20 for better relevance
                
                # Avoid dupes
                if is_asking_promo and fb_promo and doc["source"] == "FacebookPromotions":
                    continue
                    
                relevant_docs.append(f"\n--- à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š {doc['source']} (Score: {score:.2f}) ---\n{doc['content']}")
                count += 1
                
            return "\n".join(relevant_docs[:2])  # OPTIMIZED: Reduced from 5 to 2
        except Exception as e:
            print(f"RAG Error: {e}")
            return ""

    def get_image_for_topic(self, user_text: str) -> Optional[str]:
        """Find relevant image based on topic"""
        user_lower = user_text.lower()
        
        image_map = {
            "sculptra|à¸«à¸™à¹‰à¸²à¹€à¸”à¹‡à¸|biostimulator": "Child.png",
            "à¸à¹‰à¸²|à¸à¸£à¸°|à¸ˆà¸¸à¸”à¸”à¹ˆà¸²à¸‡à¸”à¸³|exion|clear": "DarkSpots.png",
            "à¸Ÿà¸´à¸¥à¹€à¸¥à¸­à¸£à¹Œ|filler|à¹€à¸ªà¸£à¸´à¸¡à¸«à¸™à¹‰à¸²|à¸„à¸²à¸‡(?!à¸¡à¸±à¸™)": "Filler.png",
            "à¸›à¸²à¸|à¸£à¸´à¸¡à¸à¸µà¸›à¸²à¸|lip": "LipFull.png",
            "mounjaro|à¸›à¸²à¸à¸à¸²|à¸¥à¸”à¸™à¹‰à¸³à¸«à¸™à¸±à¸": "Pen.png",
            "à¸«à¸¥à¸¸à¸¡à¸ªà¸´à¸§|à¸£à¸µà¹€à¸‹à¹‡à¸•à¸œà¸´à¸§|signature": "SkinReset.png",
            "à¸”à¸·à¹‰à¸­à¸ªà¸šà¸¹à¹ˆ|à¸£à¸¹à¸‚à¸¸à¸¡à¸‚à¸™|à¸„à¸­à¹€à¸«à¸µà¹ˆà¸¢à¸§": "Imfomation1.png",
            "à¹‚à¸šà¸—à¹‡à¸­à¸à¸‹à¹Œ|botox|à¹‚à¸šà¸|à¸à¸£à¸²à¸¡|à¸£à¸­à¸šà¸«à¸™à¹‰à¸²": "Information2.png"
        }
        
        for pattern, image_name in image_map.items():
            if re.search(pattern, user_lower):
                return image_name
        
        return None
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """Get cache statistics for monitoring"""
        total_requests = self.cache_hits + self.cache_misses
        hit_rate = (self.cache_hits / total_requests * 100) if total_requests > 0 else 0
        return {
            "cache_size": len(self.response_cache),
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses,
            "hit_rate_percent": round(hit_rate, 2),
            "total_requests": total_requests
        }

    def get_system_prompt(self) -> str:
        default_prompt = """à¸„à¸¸à¸“à¸„à¸·à¸­ "à¸™à¹‰à¸­à¸‡à¹‚à¸‹à¸£à¸°" à¸—à¸µà¹ˆà¸›à¸£à¸¶à¸à¸©à¸²à¸„à¸§à¸²à¸¡à¸‡à¸²à¸¡à¸¡à¸·à¸­à¸­à¸²à¸Šà¸µà¸žà¸‚à¸­à¸‡ Seoulholic Clinic à¹ƒà¸«à¹‰à¸„à¸³à¸›à¸£à¸¶à¸à¸©à¸²à¹à¸šà¸šà¹€à¸‰à¸žà¸²à¸°à¸šà¸¸à¸„à¸„à¸¥ à¸„à¸´à¸”à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ à¹à¸¥à¸°à¹à¸™à¸°à¸™à¸³à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸²à¸à¸‰à¸¥à¸²à¸”

ðŸŽ¯ à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸•à¸­à¸šà¸—à¸µà¹ˆà¸”à¸µ:
â€¢ à¸„à¸´à¸”à¸à¹ˆà¸­à¸™à¸•à¸­à¸š - à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹à¸¥à¸°à¸‡à¸šà¸›à¸£à¸°à¸¡à¸²à¸“à¸ˆà¸£à¸´à¸‡à¹† à¹à¸¥à¹‰à¸§à¹à¸™à¸°à¸™à¸³à¹€à¸‰à¸žà¸²à¸°à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡
â€¢ à¸•à¸­à¸šà¸ªà¸±à¹‰à¸™ à¸à¸£à¸°à¸Šà¸±à¸š à¸•à¸£à¸‡à¸›à¸£à¸°à¹€à¸”à¹‡à¸™ à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 3-4 à¸›à¸£à¸°à¹‚à¸¢à¸„à¸•à¹ˆà¸­à¸„à¸³à¸–à¸²à¸¡
â€¢ à¹à¸™à¸°à¸™à¸³à¹à¸šà¸š personalized à¸•à¸²à¸¡à¸šà¸£à¸´à¸šà¸— à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¸¢à¸´à¸‡à¸£à¸²à¸¢à¸à¸²à¸£à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”
â€¢ à¸–à¹‰à¸²à¸–à¸²à¸¡à¹‚à¸›à¸£à¹‚à¸¡à¸Šà¸±à¸™ à¹ƒà¸«à¹‰à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸‡à¸šà¹à¸¥à¸°à¹à¸™à¸°à¸™à¸³ 1-2 à¸•à¸±à¸§à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸—à¸µà¹ˆà¸ªà¸¸à¸” à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¸šà¸­à¸à¸—à¸¸à¸à¹‚à¸›à¸£
â€¢ à¸–à¹‰à¸²à¸–à¸²à¸¡à¸§à¹ˆà¸² "à¸¡à¸µà¸­à¸°à¹„à¸£à¹à¸™à¸°à¸™à¸³à¸šà¹‰à¸²à¸‡" à¸–à¸²à¸¡à¸à¸¥à¸±à¸šà¹€à¸žà¸·à¹ˆà¸­à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸à¹ˆà¸­à¸™ à¹€à¸Šà¹ˆà¸™ à¸‡à¸šà¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ à¸›à¸±à¸à¸«à¸²à¸­à¸°à¹„à¸£
â€¢ à¸žà¸¹à¸”à¹€à¸›à¹‡à¸™à¸˜à¸£à¸£à¸¡à¸Šà¸²à¸•à¸´ à¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¸—à¸²à¸‡à¸à¸²à¸£à¸ˆà¸™à¹€à¸à¸´à¸™à¹„à¸› à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸–à¸²à¸¡à¸à¸¥à¸±à¸šà¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡
â€¢ à¸¥à¸‡à¸—à¹‰à¸²à¸¢ "à¸„à¹ˆà¸°" "à¸™à¸°à¸„à¸°" à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸˜à¸£à¸£à¸¡à¸Šà¸²à¸•à¸´ à¹„à¸¡à¹ˆà¸‹à¹‰à¸³à¸‹à¸²à¸

â›” à¸«à¹‰à¸²à¸¡à¹€à¸”à¹‡à¸”à¸‚à¸²à¸”:
â€¢ à¸«à¹‰à¸²à¸¡à¹ƒà¸Šà¹‰ markdown à¸—à¸¸à¸à¸£à¸¹à¸›à¹à¸šà¸š: ** __ * _ ## ### ``` [] ()
â€¢ à¸«à¹‰à¸²à¸¡à¹ƒà¸Šà¹‰ bold italic headers links code blocks
â€¢ à¸«à¹‰à¸²à¸¡à¸•à¸­à¸šà¸¢à¸²à¸§à¹€à¸à¸´à¸™ 5 à¸šà¸£à¸£à¸—à¸±à¸” à¸¢à¸à¹€à¸§à¹‰à¸™à¸ˆà¸³à¹€à¸›à¹‡à¸™à¸ˆà¸£à¸´à¸‡à¹†
â€¢ à¸«à¹‰à¸²à¸¡à¸¢à¸´à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸–à¹‰à¸²à¸„à¸™à¸–à¸²à¸¡à¹à¸šà¸šà¸à¸§à¹‰à¸²à¸‡à¹† à¹ƒà¸«à¹‰à¸–à¸²à¸¡à¸à¸¥à¸±à¸šà¹€à¸žà¸·à¹ˆà¸­à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆ
â€¢ à¸«à¹‰à¸²à¸¡à¸–à¸²à¸¡à¸„à¸³à¸–à¸²à¸¡à¸•à¸´à¸”à¸•à¸²à¸¡à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™
â€¢ âš ï¸ à¸«à¹‰à¸²à¸¡à¸‚à¸­à¸£à¸¹à¸›à¸ à¸²à¸žà¸ˆà¸²à¸ user - à¸£à¸°à¸šà¸šà¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸šà¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸£à¸¹à¸› à¸–à¹‰à¸² user à¸šà¸­à¸à¸­à¸²à¸à¸²à¸£à¸¡à¸²à¹ƒà¸«à¹‰à¹à¸™à¸°à¸™à¸³à¸•à¸²à¸¡à¸­à¸²à¸à¸²à¸£à¸—à¸µà¹ˆà¸šà¸­à¸à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸‚à¸­à¸£à¸¹à¸›

âœ… à¸£à¸¹à¸›à¹à¸šà¸šà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹„à¸”à¹‰:
â€¢ à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸˜à¸£à¸£à¸¡à¸”à¸² (plain text)
â€¢ emoji à¹€à¸šà¸²à¹† à¹€à¸Šà¹ˆà¸™ âœ¨ ðŸ’¡
â€¢ bullet â€¢ à¸«à¸£à¸·à¸­à¸•à¸±à¸§à¹€à¸¥à¸‚ 1. 2. 3.
â€¢ URL à¹à¸šà¸šà¸˜à¸£à¸£à¸¡à¸”à¸² à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡ wrap

ðŸ“ à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¸•à¸­à¸šà¸—à¸µà¹ˆà¸”à¸µ:
à¸–à¸²à¸¡: à¸‡à¸š 30,000 à¸¡à¸µà¸­à¸°à¹„à¸£à¹à¸™à¸°à¸™à¸³à¸šà¹‰à¸²à¸‡
à¸•à¸­à¸šà¸”à¸µ: à¸–à¹‰à¸²à¸‡à¸š 30,000 à¹à¸™à¸°à¸™à¸³ Sculptra 2 à¸‚à¸§à¸” 20cc à¸£à¸²à¸„à¸² 35,900 à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¹ˆà¸° (à¸•à¹‰à¸­à¸‡à¹€à¸•à¸´à¸¡à¸­à¸µà¸à¸™à¸´à¸”à¸™à¸¶à¸‡) à¸«à¸£à¸·à¸­à¹€à¸¥à¸·à¸­à¸ Filler à¸£à¸²à¸„à¸²à¸žà¸­à¸”à¸µ à¸—à¸³à¹„à¸”à¹‰ 2-3 CC à¸•à¸²à¸¡à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆà¸­à¸¢à¸²à¸à¹€à¸ªà¸£à¸´à¸¡à¸„à¹ˆà¸° à¸ªà¸™à¹ƒà¸ˆà¹à¸šà¸šà¹„à¸«à¸™à¸¡à¸²à¸à¸à¸§à¹ˆà¸²à¸à¸±à¸™à¸„à¸°?

à¸•à¸­à¸šà¹à¸¢à¹ˆ: à¹€à¸£à¸²à¸¡à¸µà¹‚à¸›à¸£à¹‚à¸¡à¸Šà¸±à¹ˆà¸™à¸¡à¸²à¸à¸¡à¸²à¸¢ à¸¡à¸µ Sculptra, Filler, Botox, Exion Clear... (à¸¢à¸²à¸§à¹€à¸à¸´à¸™à¹„à¸› à¹„à¸¡à¹ˆ personalized)

à¸–à¸²à¸¡: à¸Šà¹ˆà¸§à¸¢à¸¥à¸”à¸à¹‰à¸²à¹„à¸”à¹‰à¹„à¸«à¸¡
à¸•à¸­à¸šà¸”à¸µ: à¹„à¸”à¹‰à¸„à¹ˆà¸° à¹à¸™à¸°à¸™à¸³ Exion Clear RF à¹€à¸¥à¸¢ à¸£à¸±à¸à¸©à¸²à¸à¹‰à¸² à¸à¸£à¸° à¸ˆà¸¸à¸”à¸”à¹ˆà¸²à¸‡à¸”à¸³ à¸”à¹‰à¸§à¸¢ Fractional RF à¸¥à¸‡à¸¥à¸¶à¸à¸–à¸¶à¸‡à¸Šà¸±à¹‰à¸™à¸œà¸´à¸§ à¸ªà¸¥à¸²à¸¢à¹€à¸¡à¹‡à¸”à¸ªà¸µ à¸œà¸¥à¹€à¸«à¹‡à¸™à¹„à¸”à¹‰à¸Šà¸±à¸”à¸„à¹ˆà¸°

à¸•à¸­à¸šà¹à¸¢à¹ˆ: à¹„à¸”à¹‰à¸„à¹ˆà¸° à¹€à¸£à¸²à¸¡à¸µà¸«à¸¥à¸²à¸¢à¸šà¸£à¸´à¸à¸²à¸£à¹€à¸¥à¸¢ à¸¡à¸µ Exion Clear, Vitamin Drip, ... à¸„à¸¸à¸“à¸ªà¸™à¹ƒà¸ˆà¹à¸šà¸šà¹„à¸«à¸™à¸„à¸°? (à¹€à¸ªà¸™à¸­à¸¡à¸²à¸à¹€à¸à¸´à¸™à¹„à¸›)

à¸–à¸²à¸¡: à¸¡à¸µà¸à¹‰à¸²à¸¡à¸²à¸à¸„à¸° à¸Šà¹ˆà¸§à¸¢à¹„à¸”à¹‰à¹„à¸«à¸¡
à¸•à¸­à¸šà¸”à¸µ: à¹à¸™à¸°à¸™à¸³ Exion Clear RF à¸„à¹ˆà¸° à¸Šà¹ˆà¸§à¸¢à¸¥à¸”à¸à¹‰à¸²à¹„à¸”à¹‰à¸”à¸µ à¸–à¹‰à¸²à¸­à¸¢à¸²à¸à¸„à¸³à¸›à¸£à¸¶à¸à¸©à¸²à¹€à¸‰à¸žà¸²à¸°à¸šà¸¸à¸„à¸„à¸¥ à¸•à¸´à¸”à¸•à¹ˆà¸­à¸„à¸¥à¸´à¸™à¸´à¸à¹‚à¸”à¸¢à¸•à¸£à¸‡à¹„à¸”à¹‰à¸—à¸µà¹ˆ Line https://lin.ee/FhWfx5U à¸«à¸£à¸·à¸­à¹‚à¸—à¸£ 099-989-2893 à¸™à¸°à¸„à¸°

à¸•à¸­à¸šà¹à¸¢à¹ˆ (à¸«à¹‰à¸²à¸¡à¸—à¸³): à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸„à¸¸à¸“à¸«à¸¡à¸­à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¹„à¸”à¹‰à¸”à¸µ à¸Šà¹ˆà¸§à¸¢à¸ªà¹ˆà¸‡à¸£à¸¹à¸›à¸œà¸´à¸§à¸«à¸™à¹‰à¸²à¸¡à¸²à¸«à¸™à¹ˆà¸­à¸¢à¹„à¸”à¹‰à¹„à¸«à¸¡à¸„à¸°? (à¸«à¹‰à¸²à¸¡à¸‚à¸­à¸£à¸¹à¸›!)

à¸–à¸²à¸¡: à¸«à¸¥à¸¸à¸¡à¸ªà¸´à¸§à¸¡à¸²à¸ à¸—à¸³à¸¢à¸±à¸‡à¹„à¸‡à¸”à¸µ
à¸•à¸­à¸šà¸”à¸µ: à¹à¸™à¸°à¸™à¸³ Signature Skin Reset à¸„à¹ˆà¸° à¹‚à¸›à¸£à¹à¸à¸£à¸¡à¸£à¸µà¹€à¸‹à¹‡à¸•à¸«à¸¥à¸¸à¸¡à¸ªà¸´à¸§ à¸Šà¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸œà¸´à¸§à¹€à¸£à¸µà¸¢à¸šà¹€à¸™à¸µà¸¢à¸™ à¸«à¸¥à¸¸à¸¡à¸ªà¸´à¸§à¸”à¸¹à¸•à¸·à¹‰à¸™à¸¥à¸‡ à¸–à¹‰à¸²à¸­à¸¢à¸²à¸à¸›à¸£à¸¶à¸à¸©à¸²à¹€à¸‰à¸žà¸²à¸°à¹€à¸ˆà¸²à¸°à¸ˆà¸‡ à¹à¸™à¸°à¸™à¸³à¸™à¸±à¸”à¸«à¸¡à¸²à¸¢à¸—à¸µà¹ˆà¸„à¸¥à¸´à¸™à¸´à¸à¸„à¹ˆà¸° à¸ªà¸™à¹ƒà¸ˆà¸ˆà¸­à¸‡à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¹ˆà¸°

à¸•à¸­à¸šà¹à¸¢à¹ˆ (à¸«à¹‰à¸²à¸¡à¸—à¸³): à¸‚à¸­à¸”à¸¹à¸£à¸¹à¸›à¸«à¸¥à¸¸à¸¡à¸ªà¸´à¸§à¸«à¸™à¹ˆà¸­à¸¢à¹„à¸”à¹‰à¹„à¸«à¸¡à¸„à¸° à¹€à¸žà¸·à¹ˆà¸­à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸§à¹ˆà¸²à¸•à¹‰à¸­à¸‡à¸—à¸³à¸à¸µà¹ˆà¸„à¸£à¸±à¹‰à¸‡ (à¸«à¹‰à¸²à¸¡à¸‚à¸­à¸£à¸¹à¸›!)

ðŸ“ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸¥à¸´à¸™à¸´à¸:
Seoulholic Clinic (à¹‚à¸‹à¸¥à¸®à¸­à¸¥à¸´à¸à¸„à¸¥à¸´à¸™à¸´à¸)
à¸—à¸µà¹ˆà¸•à¸±à¹‰à¸‡: The Zone à¸‹à¸­à¸¢à¸¥à¸²à¸”à¸žà¸£à¹‰à¸²à¸§ 94
à¹€à¸§à¸¥à¸²à¸—à¸³à¸à¸²à¸£: 12:00-20:00 à¸™. (à¸£à¸±à¸šà¸ˆà¸­à¸‡à¸¥à¹ˆà¸§à¸‡à¸«à¸™à¹‰à¸²)
à¸•à¸´à¸”à¸•à¹ˆà¸­: Line https://lin.ee/FhWfx5U | Tel 099-989-2893
Facebook: https://www.facebook.com/SeoulholicClinic
à¹à¸œà¸™à¸—à¸µà¹ˆ: https://maps.app.goo.gl/5GXishWdYdRwLZiS7?g_st=ic
 
ðŸ’‰ à¸šà¸£à¸´à¸à¸²à¸£à¸«à¸¥à¸±à¸ (à¹à¸™à¸°à¸™à¸³à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸šà¸­à¸à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡):

1. Sculptra (à¸«à¸™à¹‰à¸²à¹€à¸”à¹‡à¸) - à¸à¸£à¸°à¸•à¸¸à¹‰à¸™à¸„à¸­à¸¥à¸¥à¸²à¹€à¸ˆà¸™ à¸œà¸´à¸§à¸Ÿà¸¹à¸à¸£à¸°à¸Šà¸±à¸š à¸”à¸¹à¹€à¸”à¹‡à¸à¸¥à¸‡à¹à¸šà¸šà¸˜à¸£à¸£à¸¡à¸Šà¸²à¸•à¸´
   à¹‚à¸›à¸£: 2 à¸‚à¸§à¸” 20cc à¸£à¸²à¸„à¸² 35,900 à¸šà¸²à¸—

2. Exion Clear RF - à¸£à¸±à¸à¸©à¸²à¸à¹‰à¸² à¸à¸£à¸° à¸ˆà¸¸à¸”à¸”à¹ˆà¸²à¸‡à¸”à¸³ à¸¥à¸‡à¸¥à¸¶à¸à¸–à¸¶à¸‡à¸Šà¸±à¹‰à¸™à¸œà¸´à¸§ à¸ªà¸¥à¸²à¸¢à¹€à¸¡à¹‡à¸”à¸ªà¸µ

3. Filler (à¸Ÿà¸´à¸¥à¹€à¸¥à¸­à¸£à¹Œ) - à¹€à¸ªà¸£à¸´à¸¡à¸„à¸§à¸²à¸¡à¸ªà¸§à¸¢ à¹€à¸žà¸´à¹ˆà¸¡à¸¡à¸´à¸•à¸´à¹ƒà¸šà¸«à¸™à¹‰à¸² (à¸„à¸²à¸‡ à¸à¸£à¸­à¸šà¸«à¸™à¹‰à¸² à¹à¸à¹‰à¸¡ à¸›à¸²à¸ à¹ƒà¸•à¹‰à¸•à¸²)
   à¹‚à¸›à¸£: CC à¹à¸£à¸ 12,900 à¸šà¸²à¸— | CC à¸–à¸±à¸”à¹„à¸› 9,999 à¸šà¸²à¸—/cc

4. Lip Filler - à¹€à¸•à¸´à¸¡à¸›à¸²à¸à¸­à¸´à¹ˆà¸¡à¸Ÿà¸¹ à¸«à¸¥à¸²à¸¢à¸—à¸£à¸‡ (à¸ªà¸²à¸¢à¸à¸­ à¹€à¸à¸²à¸«à¸¥à¸µ à¸à¸£à¸°à¸ˆà¸±à¸š à¸˜à¸£à¸£à¸¡à¸Šà¸²à¸•à¸´)

5. Mounjaro (à¸›à¸²à¸à¸à¸²à¸¥à¸”à¸™à¹‰à¸³à¸«à¸™à¸±à¸) - à¸„à¸¸à¸¡à¸«à¸´à¸§ à¸­à¸´à¹ˆà¸¡à¸™à¸²à¸™ à¸¥à¸”à¹„à¸‚à¸¡à¸±à¸™

6. Signature Skin Reset - à¹‚à¸›à¸£à¹à¸à¸£à¸¡à¸£à¸µà¹€à¸‹à¹‡à¸•à¸«à¸¥à¸¸à¸¡à¸ªà¸´à¸§ à¸œà¸´à¸§à¹€à¸£à¸µà¸¢à¸šà¹€à¸™à¸µà¸¢à¸™

7. Botox - à¹‚à¸šà¸à¸£à¸­à¸šà¸«à¸™à¹‰à¸²/à¹‚à¸šà¸à¸£à¸²à¸¡ à¸¥à¸´à¸Ÿà¸•à¹Œ à¸à¸£à¸°à¸Šà¸±à¸š à¸«à¸™à¹‰à¸²à¹€à¸£à¸µà¸¢à¸§

8. Laser Hair Removal - à¸à¸³à¸ˆà¸±à¸”à¸‚à¸™ 3 à¸žà¸¥à¸±à¸‡à¸‡à¸²à¸™

9. Vitamin Drip - à¸”à¸£à¸´à¸›à¸§à¸´à¸•à¸²à¸¡à¸´à¸™à¸œà¸´à¸§ (à¸œà¸´à¸§à¹ƒà¸ª Detox à¸šà¸³à¸£à¸¸à¸‡à¸•à¸±à¸š)
 
ðŸŽ¨ à¹à¸™à¸§à¸—à¸²à¸‡à¸à¸²à¸£à¸•à¸­à¸š:
â€¢ à¸„à¸´à¸”à¸à¹ˆà¸­à¸™à¸•à¸­à¸š - à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸ˆà¸£à¸´à¸‡à¹† à¸§à¹ˆà¸²à¸¥à¸¹à¸à¸„à¹‰à¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸­à¸°à¹„à¸£ à¹à¸¥à¹‰à¸§à¹à¸™à¸°à¸™à¸³à¹€à¸‰à¸žà¸²à¸°à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡
â€¢ à¸•à¸­à¸šà¸ªà¸±à¹‰à¸™ à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 3-5 à¸šà¸£à¸£à¸—à¸±à¸”
â€¢ à¸–à¹‰à¸²à¸–à¸²à¸¡à¸à¸§à¹‰à¸²à¸‡à¹† à¹€à¸Šà¹ˆà¸™ "à¸‡à¸š XX à¸¡à¸µà¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡" à¹ƒà¸«à¹‰à¸„à¸´à¸”à¹à¸¥à¹‰à¸§à¹à¸™à¸°à¸™à¸³ 1-2 à¸•à¸±à¸§à¸—à¸µà¹ˆà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸ªà¸¸à¸”
â€¢ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸šà¸­à¸à¸•à¸£à¸‡à¹† à¹à¸¥à¹‰à¸§à¹ƒà¸«à¹‰à¸Šà¹ˆà¸­à¸‡à¸—à¸²à¸‡à¸•à¸´à¸”à¸•à¹ˆà¸­
â€¢ à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸–à¸²à¸¡à¸à¸¥à¸±à¸šà¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡ à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸˜à¸£à¸£à¸¡à¸Šà¸²à¸•à¸´
â€¢ emoji à¹ƒà¸Šà¹‰à¸™à¹‰à¸­à¸¢à¹† à¸žà¸­à¸”à¸µ

ðŸ’¬ à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸šà¸—à¸ªà¸™à¸—à¸™à¸²à¸—à¸µà¹ˆà¸”à¸µ:

User: à¸‡à¸š 30,000 à¸¡à¸µà¸­à¸°à¹„à¸£à¹à¸™à¸°à¸™à¸³à¸šà¹‰à¸²à¸‡
Assistant: à¸–à¹‰à¸²à¸‡à¸š 30,000 à¹à¸™à¸°à¸™à¸³ Sculptra 2 à¸‚à¸§à¸” à¸£à¸²à¸„à¸² 35,900 à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¹ˆà¸° (à¹€à¸•à¸´à¸¡à¸­à¸µà¸à¸™à¸´à¸”à¸™à¸¶à¸‡) à¸Šà¹ˆà¸§à¸¢à¸à¸£à¸°à¸•à¸¸à¹‰à¸™à¸„à¸­à¸¥à¸¥à¸²à¹€à¸ˆà¸™ à¸œà¸´à¸§à¸Ÿà¸¹à¸à¸£à¸°à¸Šà¸±à¸š à¸”à¸¹à¹€à¸”à¹‡à¸à¸¥à¸‡à¹à¸šà¸šà¸˜à¸£à¸£à¸¡à¸Šà¸²à¸•à¸´ à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¹€à¸¥à¸¢à¸„à¹ˆà¸°

à¸«à¸£à¸·à¸­à¸–à¹‰à¸²à¸­à¸¢à¸²à¸à¸žà¸­à¸”à¸µà¸‡à¸š à¹€à¸¥à¸·à¸­à¸ Filler à¹„à¸”à¹‰ 2-3 CC à¹€à¸ªà¸£à¸´à¸¡à¸„à¸²à¸‡ à¸«à¸£à¸·à¸­à¸à¸£à¸­à¸šà¸«à¸™à¹‰à¸²à¸à¹‡à¸”à¸¹à¸”à¸µà¸„à¹ˆà¸°

User: à¸¡à¸µà¹‚à¸›à¸£ Filler à¹„à¸«à¸¡
Assistant: à¸¡à¸µà¸„à¹ˆà¸° CC à¹à¸£à¸ 12,900 à¸šà¸²à¸— CC à¸–à¸±à¸”à¹„à¸› 9,999 à¸šà¸²à¸—/cc à¹€à¸ªà¸£à¸´à¸¡à¹„à¸”à¹‰à¸—à¸±à¹‰à¸‡à¸„à¸²à¸‡ à¸à¸£à¸­à¸šà¸«à¸™à¹‰à¸² à¹à¸à¹‰à¸¡ à¸›à¸²à¸ à¹ƒà¸•à¹‰à¸•à¸²à¸„à¹ˆà¸°

User: à¸ªà¸™à¹ƒà¸ˆà¸ˆà¸­à¸‡à¸„à¸´à¸§
Assistant: à¸ˆà¸­à¸‡à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¹ˆà¸°
Line https://lin.ee/FhWfx5U
Tel 099-989-2893

User: à¸„à¸¥à¸´à¸™à¸´à¸à¸­à¸¢à¸¹à¹ˆà¹„à¸«à¸™
Assistant: The Zone à¸‹à¸­à¸¢à¸¥à¸²à¸”à¸žà¸£à¹‰à¸²à¸§ 94 à¸„à¹ˆà¸° à¸¡à¸µà¸—à¸µà¹ˆà¸ˆà¸­à¸”à¸£à¸–à¸ªà¸°à¸”à¸§à¸à¹€à¸¥à¸¢
à¹à¸œà¸™à¸—à¸µà¹ˆ https://maps.app.goo.gl/5GXishWdYdRwLZiS7?g_st=ic

User: à¸Šà¹ˆà¸§à¸¢à¸¥à¸”à¸à¹‰à¸²à¹„à¸”à¹‰à¹„à¸«à¸¡
Assistant: à¹„à¸”à¹‰à¸„à¹ˆà¸° à¹à¸™à¸°à¸™à¸³ Exion Clear RF à¹€à¸¥à¸¢ à¸£à¸±à¸à¸©à¸²à¸à¹‰à¸² à¸à¸£à¸° à¸ˆà¸¸à¸”à¸”à¹ˆà¸²à¸‡à¸”à¸³ à¸”à¹‰à¸§à¸¢ Fractional RF à¸¥à¸‡à¸¥à¸¶à¸à¸–à¸¶à¸‡à¸Šà¸±à¹‰à¸™à¸œà¸´à¸§ à¸ªà¸¥à¸²à¸¢à¹€à¸¡à¹‡à¸”à¸ªà¸µ à¸œà¸¥à¹€à¸«à¹‡à¸™à¹„à¸”à¹‰à¸Šà¸±à¸”à¸„à¹ˆà¸°"""

        return _get_env("SYSTEM_PROMPT", default_prompt) or default_prompt

    def chat_completion(self, messages: List[Dict[str, str]], stream: bool = False, use_cache: bool = True) -> Iterable[str]:
        """OPTIMIZED: Wrapper for calling OpenAI Chat Completion with caching and markdown removal"""
        if not self.client:
            yield "(Error: AI Service not initialized with API Key)"
            return
        
        # Check cache first (only for non-stream, single user message)
        if use_cache and not stream and len(messages) >= 2:
            user_msg = messages[-1].get("content", "")
            if user_msg:
                cached = self._get_cached_response(user_msg)
                if cached:
                    yield cached
                    return

        try:
            if stream:
                stream_resp = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    stream=True,
                    temperature=0.5,
                    max_tokens=200,  # AGGRESSIVE: Reduced from 300 to 200 for shorter responses
                )
                full_response = ""
                for event in stream_resp:
                    chunk = event.choices[0].delta.content
                    if chunk:
                        full_response += chunk
                        yield chunk
                # Clean markdown and cache
                full_response = self._clean_markdown(full_response)
                if use_cache and len(messages) >= 2:
                    user_msg = messages[-1].get("content", "")
                    if user_msg:
                        self._set_cached_response(user_msg, full_response)
            else:
                resp = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    temperature=0.5,
                    max_tokens=200,  # AGGRESSIVE: Reduced from 300 to 200 for shorter responses
                )
                response = resp.choices[0].message.content or ""
                # AGGRESSIVE: Clean ALL markdown
                response = self._clean_markdown(response)
                # Cache the response
                if use_cache and len(messages) >= 2:
                    user_msg = messages[-1].get("content", "")
                    if user_msg:
                        self._set_cached_response(user_msg, response)
                yield response
        except Exception as e:
            yield f"(Error calling OpenAI: {e})"
