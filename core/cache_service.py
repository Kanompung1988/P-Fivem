"""
Response Caching Service
à¸¥à¸” latency 80% à¹à¸¥à¸° cost 60% à¸”à¹‰à¸§à¸¢ Redis cache

Hit rate à¸„à¸²à¸”à¸à¸²à¸£à¸“à¹Œ: 70-80% (à¸„à¸³à¸–à¸²à¸¡à¸‹à¹‰à¸³à¹† à¹€à¸Šà¹ˆà¸™ "à¸£à¸²à¸„à¸² MTS", "à¹‚à¸›à¸£à¹‚à¸¡à¸Šà¸±à¹ˆà¸™")
"""

import hashlib
import json
import os
from typing import Optional, Dict, Any
from functools import wraps
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Try to import redis, fallback to in-memory cache
try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    logger.warning(" Redis not installed, using in-memory cache")


class ResponseCache:
    """Caching service with Redis or in-memory fallback"""
    
    def __init__(self, use_redis: bool = True):
        """
        Initialize cache service
        
        Args:
            use_redis: Use Redis if available, else use in-memory dict
        """
        self.use_redis = use_redis and REDIS_AVAILABLE
        
        if self.use_redis:
            try:
                self.redis_client = redis.Redis(
                    host=os.getenv('REDIS_HOST', 'localhost'),
                    port=int(os.getenv('REDIS_PORT', 6379)),
                    db=int(os.getenv('REDIS_DB', 0)),
                    decode_responses=True,
                    socket_timeout=5,
                    socket_connect_timeout=5
                )
                # Test connection
                self.redis_client.ping()
                logger.info(" Connected to Redis cache")
            except Exception as e:
                logger.warning(f" Redis connection failed: {e}. Using in-memory cache")
                self.use_redis = False
                self._memory_cache = {}
        else:
            self._memory_cache = {}
            logger.info(" Using in-memory cache")
        
        # Cache statistics
        self.stats = {
            "hits": 0,
            "misses": 0,
            "sets": 0
        }
    
    def _normalize_question(self, question: str) -> str:
        """Normalize à¸„à¸³à¸–à¸²à¸¡à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰ match à¹„à¸”à¹‰à¸”à¸µà¸‚à¸¶à¹‰à¸™"""
        # à¸¥à¸š whitespace, lowercase, à¸¥à¸šà¸­à¸±à¸à¸‚à¸£à¸°à¸žà¸´à¹€à¸¨à¸©
        normalized = question.lower().strip()
        # à¸¥à¸šà¸„à¸³à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸ªà¸³à¸„à¸±à¸ (optional)
        normalized = normalized.replace("à¸„à¸°", "").replace("à¸„à¹ˆà¸°", "")
        normalized = normalized.replace("à¸„à¸£à¸±à¸š", "").replace("à¸™à¹ˆà¸°", "")
        return normalized
    
    def get_cache_key(self, question: str, user_id: str = None) -> str:
        """
        à¸ªà¸£à¹‰à¸²à¸‡ cache key à¸ˆà¸²à¸à¸„à¸³à¸–à¸²à¸¡
        
        Args:
            question: à¸„à¸³à¸–à¸²à¸¡à¸ˆà¸²à¸à¸¥à¸¹à¸à¸„à¹‰à¸²
            user_id: User ID (optional, à¸ªà¸³à¸«à¸£à¸±à¸š personalized cache)
        
        Returns:
            MD5 hash à¸‚à¸­à¸‡à¸„à¸³à¸–à¸²à¸¡
        """
        normalized = self._normalize_question(question)
        
        # à¹€à¸žà¸´à¹ˆà¸¡ user_id à¸–à¹‰à¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ personalized cache
        if user_id:
            cache_string = f"{user_id}:{normalized}"
        else:
            cache_string = normalized
        
        return hashlib.md5(cache_string.encode('utf-8')).hexdigest()
    
    def get(self, question: str, user_id: str = None) -> Optional[Dict[str, Any]]:
        """
        à¸”à¸¶à¸‡ cached response
        
        Args:
            question: à¸„à¸³à¸–à¸²à¸¡
            user_id: User ID (optional)
        
        Returns:
            Cached response dict à¸«à¸£à¸·à¸­ None à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ
        """
        key = self.get_cache_key(question, user_id)
        
        try:
            if self.use_redis:
                cached = self.redis_client.get(key)
                if cached:
                    self.stats["hits"] += 1
                    logger.info(f" Cache HIT: {question[:50]}...")
                    return json.loads(cached)
            else:
                if key in self._memory_cache:
                    entry = self._memory_cache[key]
                    # Check expiry
                    if entry["expires_at"] > time.time():
                        self.stats["hits"] += 1
                        logger.info(f" Cache HIT (memory): {question[:50]}...")
                        return entry["data"]
                    else:
                        # Expired, remove
                        del self._memory_cache[key]
            
            self.stats["misses"] += 1
            logger.info(f" Cache MISS: {question[:50]}...")
            return None
            
        except Exception as e:
            logger.error(f"Cache get error: {e}")
            return None
    
    def set(
        self, 
        question: str, 
        response: Dict[str, Any], 
        ttl: int = 3600,
        user_id: str = None
    ):
        """
        à¹€à¸à¹‡à¸š response à¹„à¸§à¹‰à¹ƒà¸™ cache
        
        Args:
            question: à¸„à¸³à¸–à¸²à¸¡
            response: Response dict à¸—à¸µà¹ˆà¸ˆà¸°à¹€à¸à¹‡à¸š
            ttl: Time to live (seconds) default 1 hour
            user_id: User ID (optional)
        """
        key = self.get_cache_key(question, user_id)
        
        try:
            if self.use_redis:
                self.redis_client.setex(
                    key,
                    ttl,
                    json.dumps(response, ensure_ascii=False)
                )
            else:
                self._memory_cache[key] = {
                    "data": response,
                    "expires_at": time.time() + ttl
                }
            
            self.stats["sets"] += 1
            logger.info(f"[SAVED] Cached: {question[:50]}... (TTL: {ttl}s)")
            
        except Exception as e:
            logger.error(f"Cache set error: {e}")
    
    def invalidate(self, question: str, user_id: str = None):
        """à¸¥à¸š cache entry"""
        key = self.get_cache_key(question, user_id)
        
        try:
            if self.use_redis:
                self.redis_client.delete(key)
            else:
                if key in self._memory_cache:
                    del self._memory_cache[key]
            logger.info(f"ðŸ—‘ï¸ Invalidated cache: {question[:50]}...")
        except Exception as e:
            logger.error(f"Cache invalidate error: {e}")
    
    def clear_all(self):
        """à¸¥à¸š cache à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” (à¹ƒà¸Šà¹‰à¹€à¸¡à¸·à¹ˆà¸­à¸­à¸±à¸›à¹€à¸”à¸• knowledge base)"""
        try:
            if self.use_redis:
                # à¸¥à¸šà¹€à¸‰à¸žà¸²à¸° keys à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ MD5 hash
                for key in self.redis_client.scan_iter(match="*"):
                    self.redis_client.delete(key)
            else:
                self._memory_cache.clear()
            logger.info("ðŸ—‘ï¸ Cleared all cache")
        except Exception as e:
            logger.error(f"Cache clear error: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """à¸”à¸¹ cache statistics"""
        total_requests = self.stats["hits"] + self.stats["misses"]
        hit_rate = (self.stats["hits"] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            "hits": self.stats["hits"],
            "misses": self.stats["misses"],
            "sets": self.stats["sets"],
            "total_requests": total_requests,
            "hit_rate_percent": round(hit_rate, 2),
            "cache_type": "Redis" if self.use_redis else "In-Memory"
        }


# Decorator à¸ªà¸³à¸«à¸£à¸±à¸š auto-cache
def cached_response(ttl: int = 3600):
    """
    Decorator à¸ªà¸³à¸«à¸£à¸±à¸š cache function responses
    
    Usage:
        @cached_response(ttl=1800)
        def answer_question(question: str):
            return expensive_computation(question)
    """
    def decorator(func):
        cache = ResponseCache()
        
        @wraps(func)
        def wrapper(question: str, *args, **kwargs):
            # Check cache
            cached = cache.get(question)
            if cached:
                cached["from_cache"] = True
                return cached
            
            # Call function
            result = func(question, *args, **kwargs)
            
            # Cache result
            if isinstance(result, dict):
                cache.set(question, result, ttl)
                result["from_cache"] = False
            
            return result
        
        return wrapper
    return decorator


# Singleton instance
_cache_instance = None

def get_cache_service() -> ResponseCache:
    """Get singleton cache service"""
    global _cache_instance
    if _cache_instance is None:
        _cache_instance = ResponseCache()
    return _cache_instance


if __name__ == "__main__":
    # Test cache
    cache = get_cache_service()
    
    # Test set/get
    test_question = "MTS PDRN à¸£à¸²à¸„à¸²à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆà¸„à¸°"
    test_response = {
        "answer": "MTS PDRN à¸£à¸²à¸„à¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ 3,500 à¸šà¸²à¸—à¸„à¹ˆà¸°",
        "confidence": 0.95
    }
    
    # Set cache
    cache.set(test_question, test_response, ttl=60)
    
    # Get cache (should hit)
    result = cache.get(test_question)
    print(f"Cached result: {result}")
    
    # Test similar question (should hit due to normalization)
    similar = cache.get("mts pdrn à¸£à¸²à¸„à¸²à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆà¸„à¹ˆà¸°")
    print(f"Similar question result: {similar}")
    
    # Stats
    print(f"\nCache stats: {cache.get_stats()}")
