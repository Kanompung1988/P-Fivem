"""
Large-Scale Test Dataset Generator
à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸¸à¸”à¸„à¸³à¸–à¸²à¸¡à¸—à¸”à¸ªà¸­à¸š 800+ à¸‚à¹‰à¸­ à¹à¸šà¸šà¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡
"""

import json
import random
from pathlib import Path
from typing import List, Dict

# Services with variations
SERVICES = {
    "MTS PDRN": ["MTS PDRN", "MTS", "PDRN", "mts pdrn", "à¹€à¸­à¹‡à¸¡à¸—à¸µà¹€à¸­à¸ª", "à¸žà¸µà¸”à¸µà¸­à¸²à¸£à¹Œà¹€à¸­à¹‡à¸™", "Micro Needle", "microneedle", "à¹€à¸‚à¹‡à¸¡à¹€à¸¥à¹‡à¸"],
    "Skin Reset": ["Skin Reset", "à¸ªà¸à¸´à¸™ à¸£à¸µà¹€à¸‹à¹‡à¸•", "skin reset", "skinreset", "à¸œà¸´à¸§à¸£à¸µà¹€à¸‹à¹‡à¸•", "reset à¸œà¸´à¸§"],
    "Lip Filler": ["Lip Filler", "à¸¥à¸´à¸›à¸Ÿà¸´à¸¥à¹€à¸¥à¸­à¸£à¹Œ", "lip filler", "à¸Ÿà¸´à¸¥à¹€à¸¥à¸­à¸£à¹Œà¸›à¸²à¸", "à¸‰à¸µà¸”à¸›à¸²à¸", "à¹€à¸•à¸´à¸¡à¸›à¸²à¸", "à¸›à¸²à¸à¸šà¸²à¸‡"],
    "Meso Fat": ["Meso Fat", "à¹€à¸¡à¹‚à¸ªà¹à¸Ÿà¸—", "meso fat", "mesofat", "à¸¥à¸”à¹„à¸‚à¸¡à¸±à¸™", "à¸¥à¸”à¸«à¸™à¹‰à¸²à¸­à¸§à¸š", "à¹€à¸¡à¹‚à¸ªà¸«à¸™à¹‰à¸²"],
    "Dark Spots": ["Dark Spots", "à¸à¹‰à¸²", "à¸à¸£à¸°", "à¸ˆà¸¸à¸”à¸”à¹ˆà¸²à¸‡à¸”à¸³", "à¸£à¸­à¸¢à¸”à¸³", "à¸œà¸´à¸§à¸„à¸¥à¹‰à¸³", "à¸«à¸™à¹‰à¸²à¸”à¸³", "à¸£à¸±à¸à¸©à¸²à¸à¹‰à¸²", "à¸£à¸±à¸à¸©à¸²à¸à¸£à¸°"],
    "Essential Glow": ["Essential Glow", "Essential Glow Drip", "Glow Drip", "à¹€à¸­à¸ªà¹€à¸‹à¸™à¹€à¸Šà¸µà¸¢à¸¥ à¹‚à¸à¸¥à¸§à¹Œ", "drip à¸œà¸´à¸§à¸‚à¸²à¸§"]
}

# Question templates
QUESTION_TEMPLATES = {
    "what_is": [
        "{service} à¸„à¸·à¸­à¸­à¸°à¹„à¸£", "{service} à¸„à¸·à¸­à¸­à¸°à¹„à¸£à¸„à¸°", "{service} à¸—à¸³à¸­à¸°à¹„à¸£",
        "à¸­à¸¢à¸²à¸à¸£à¸¹à¹‰à¸§à¹ˆà¸² {service} à¸„à¸·à¸­à¸­à¸°à¹„à¸£", "à¸Šà¹ˆà¸§à¸¢à¸­à¸˜à¸´à¸šà¸²à¸¢ {service} à¸«à¸™à¹ˆà¸­à¸¢",
        "{service} à¹ƒà¸Šà¹‰à¸—à¸³à¸­à¸°à¹„à¸£à¸„à¸°", "à¸šà¸­à¸à¸«à¸™à¹ˆà¸­à¸¢à¸§à¹ˆà¸² {service} à¸„à¸·à¸­à¸­à¸°à¹„à¸£",
        "{service} à¸¡à¸±à¸™à¸„à¸·à¸­à¸­à¸°à¹„à¸£à¸„à¸£à¸±à¸š",
    ],
    "price": [
        "{service} à¸£à¸²à¸„à¸²à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ", "{service} à¸£à¸²à¸„à¸²à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆà¸„à¸°", "à¸£à¸²à¸„à¸² {service}",
        "à¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢ {service}", "{service} à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ", "à¸—à¸³ {service} à¸£à¸²à¸„à¸²à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ",
        "à¸­à¸¢à¸²à¸à¸£à¸¹à¹‰à¸£à¸²à¸„à¸² {service}", "{service} à¸„à¸´à¸”à¸¢à¸±à¸‡à¹„à¸‡", "à¸‡à¸š {service} à¹€à¸—à¹ˆà¸²à¹„à¸£",
        "à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰à¹€à¸‡à¸´à¸™à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆà¸ªà¸³à¸«à¸£à¸±à¸š {service}",
    ],
    "sessions": [
        "{service} à¸—à¸³à¸à¸µà¹ˆà¸„à¸£à¸±à¹‰à¸‡", "{service} à¸•à¹‰à¸­à¸‡à¸—à¸³à¸à¸µà¹ˆà¸„à¸£à¸±à¹‰à¸‡à¸–à¸¶à¸‡à¸ˆà¸°à¹€à¸«à¹‡à¸™à¸œà¸¥",
        "à¸—à¸³ {service} à¸à¸µà¹ˆà¸„à¸£à¸±à¹‰à¸‡à¸”à¸µ", "à¹à¸™à¸°à¸™à¸³ {service} à¸à¸µà¹ˆà¸„à¸£à¸±à¹‰à¸‡",
        "{service} session à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ", "à¸„à¸§à¸£à¸—à¸³ {service} à¸à¸µà¹ˆà¸£à¸­à¸š",
        "{service} à¸—à¸³à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§à¸žà¸­à¹„à¸«à¸¡",
    ]
}

# Skin problems
SKIN_PROBLEMS = [
    "à¹à¸«à¹‰à¸‡", "à¸¡à¸±à¸™", "à¸œà¸ªà¸¡", "à¹à¸žà¹‰à¸‡à¹ˆà¸²à¸¢", "à¸ªà¸´à¸§", "à¸£à¸­à¸¢à¸ªà¸´à¸§", "à¸£à¸¹à¸‚à¸¸à¸¡à¸‚à¸™à¸à¸§à¹‰à¸²à¸‡",
    "à¸£à¸´à¹‰à¸§à¸£à¸­à¸¢", "à¸«à¸¢à¹ˆà¸­à¸™à¸„à¸¥à¹‰à¸­à¸¢", "à¹„à¸¡à¹ˆà¸à¸£à¸°à¸ˆà¹ˆà¸²à¸‡à¹ƒà¸ª", "à¸ˆà¸¸à¸”à¸”à¹ˆà¸²à¸‡à¸”à¸³", "à¸à¹‰à¸²", "à¸à¸£à¸°"
]

def generate_basic_questions() -> List[Dict]:
    """à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸–à¸²à¸¡à¸žà¸·à¹‰à¸™à¸à¸²à¸™"""
    questions = []
    qid = 1
    
    for service_name, variations in SERVICES.items():
        for variation in variations:
            # What is
            for template in QUESTION_TEMPLATES["what_is"]:
                questions.append({
                    "id": f"gen_{qid:04d}",
                    "category": "services_pricing",
                    "question": template.format(service=variation),
                    "expected_keywords": [service_name.split()[0], "à¸šà¸£à¸´à¸à¸²à¸£"],
                    "should_not_contain": ["à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥"],
                    "difficulty": "easy",
                    "generated": True
                })
                qid += 1
            
            # Price
            for template in QUESTION_TEMPLATES["price"]:
                questions.append({
                    "id": f"gen_{qid:04d}",
                    "category": "services_pricing",
                    "question": template.format(service=variation),
                    "expected_keywords": ["à¸£à¸²à¸„à¸²", "à¸šà¸²à¸—"],
                    "should_not_contain": ["à¸Ÿà¸£à¸µ"],
                    "difficulty": "easy",
                    "generated": True
                })
                qid += 1
            
            # Sessions
            for template in QUESTION_TEMPLATES["sessions"]:
                questions.append({
                    "id": f"gen_{qid:04d}",
                    "category": "services_pricing",
                    "question": template.format(service=variation),
                    "expected_keywords": ["à¸„à¸£à¸±à¹‰à¸‡"],
                    "should_not_contain": [],
                    "difficulty": "medium",
                    "generated": True
                })
                qid += 1
    
    return questions

def generate_comparison_questions() -> List[Dict]:
    """à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸–à¸²à¸¡à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š"""
    questions = []
    qid = 5000
    service_names = list(SERVICES.keys())
    
    templates = [
        "{s1} à¸à¸±à¸š {s2} à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™à¸¢à¸±à¸‡à¹„à¸‡",
        "à¹€à¸¥à¸·à¸­à¸ {s1} à¸«à¸£à¸·à¸­ {s2} à¸”à¸µ",
        "{s1} vs {s2}",
        "à¸„à¸§à¸£à¸—à¸³ {s1} à¸«à¸£à¸·à¸­ {s2}",
    ]
    
    for i, s1 in enumerate(service_names):
        for s2 in service_names[i+1:]:
            for template in templates:
                questions.append({
                    "id": f"cmp_{qid:04d}",
                    "category": "comparison",
                    "question": template.format(s1=s1, s2=s2),
                    "expected_keywords": [s1.split()[0], s2.split()[0]],
                    "should_not_contain": [],
                    "difficulty": "hard",
                    "generated": True
                })
                qid += 1
    
    return questions

def generate_problem_questions() -> List[Dict]:
    """à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸–à¸²à¸¡à¸•à¸²à¸¡à¸›à¸±à¸à¸«à¸²à¸œà¸´à¸§"""
    questions = []
    qid = 6000
    
    templates = [
        "à¸œà¸´à¸§{p} à¸„à¸§à¸£à¸—à¸³à¸­à¸°à¹„à¸£à¸”à¸µ", "à¸¡à¸µà¸›à¸±à¸à¸«à¸²{p} à¹à¸™à¸°à¸™à¸³à¸šà¸£à¸´à¸à¸²à¸£à¸­à¸°à¹„à¸£",
        "à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²{p} à¸—à¸³à¸­à¸°à¹„à¸£à¸”à¸µ", "{p}à¸¡à¸²à¸ à¸•à¹‰à¸­à¸‡à¸—à¸³à¸­à¸°à¹„à¸£",
        "à¸œà¸´à¸§à¸«à¸™à¹‰à¸²{p} à¹ƒà¸Šà¹‰à¸šà¸£à¸´à¸à¸²à¸£à¸­à¸°à¹„à¸£", "à¸£à¸±à¸à¸©à¸²{p} à¸”à¹‰à¸§à¸¢à¸­à¸°à¹„à¸£",
    ]
    
    for problem in SKIN_PROBLEMS:
        for template in templates:
            questions.append({
                "id": f"prob_{qid:04d}",
                "category": "complex",
                "question": template.format(p=problem),
                "expected_keywords": ["à¹à¸™à¸°à¸™à¸³", "à¸šà¸£à¸´à¸à¸²à¸£"],
                "should_not_contain": [],
                "difficulty": "hard",
                "generated": True
            })
            qid += 1
    
    return questions

def generate_budget_questions() -> List[Dict]:
    """à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸–à¸²à¸¡à¸‡à¸šà¸›à¸£à¸°à¸¡à¸²à¸“"""
    questions = []
    qid = 7000
    budgets = [3000, 5000, 10000, 15000, 20000, 30000, 50000]
    
    templates = [
        "à¸‡à¸š {b} à¸šà¸²à¸— à¸—à¸³à¸­à¸°à¹„à¸£à¹„à¸”à¹‰à¸šà¹‰à¸²à¸‡",
        "à¸¡à¸µà¹€à¸‡à¸´à¸™ {b} à¹à¸™à¸°à¸™à¸³à¸šà¸£à¸´à¸à¸²à¸£à¸­à¸°à¹„à¸£",
        "à¸–à¹‰à¸²à¸¡à¸µà¸‡à¸š {b} à¸„à¸§à¸£à¸—à¸³à¸­à¸°à¹„à¸£",
        "à¸£à¸²à¸„à¸²à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ {b} à¸¡à¸µà¸šà¸£à¸´à¸à¸²à¸£à¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡",
    ]
    
    for budget in budgets:
        for template in templates:
            questions.append({
                "id": f"bud_{qid:04d}",
                "category": "complex",
                "question": template.format(b=budget),
                "expected_keywords": ["à¸£à¸²à¸„à¸²", "à¸šà¸£à¸´à¸à¸²à¸£"],
                "should_not_contain": [],
                "difficulty": "hard",
                "generated": True
            })
            qid += 1
    
    return questions

def generate_promotion_questions() -> List[Dict]:
    """à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸–à¸²à¸¡à¹‚à¸›à¸£à¹‚à¸¡à¸Šà¸±à¹ˆà¸™"""
    questions = []
    qid = 8000
    
    promos = ["Essential Glow Drip 5 Sessions", "Meso Promotion 5 Times 999", "Pro Filler 3990", "Buy 1 Get 1"]
    
    templates = [
        "à¸¡à¸µà¹‚à¸›à¸£à¹‚à¸¡à¸Šà¸±à¹ˆà¸™à¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡", "à¹‚à¸›à¸£à¸§à¸±à¸™à¸™à¸µà¹‰à¸¡à¸µà¸­à¸°à¹„à¸£", "à¸ªà¹ˆà¸§à¸™à¸¥à¸”à¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡",
        "à¸¡à¸µà¹‚à¸›à¸£à¹„à¸«à¸¡", "à¸Šà¹ˆà¸§à¸‡à¸™à¸µà¹‰à¸¡à¸µà¹‚à¸›à¸£à¹„à¸«à¸¡",
    ]
    
    # Generic
    for template in templates:
        for suffix in ["", "à¸„à¸°", "à¸„à¸£à¸±à¸š", "à¸šà¹‰à¸²à¸‡"]:
            questions.append({
                "id": f"prm_{qid:04d}",
                "category": "promotions",
                "question": f"{template}{suffix}",
                "expected_keywords": ["à¹‚à¸›à¸£à¹‚à¸¡à¸Šà¸±à¹ˆà¸™"],
                "should_not_contain": [],
                "difficulty": "easy",
                "generated": True
            })
            qid += 1
    
    # Specific
    for promo in promos:
        for t in ["{p} à¸„à¸·à¸­à¸­à¸°à¹„à¸£", "{p} à¸£à¸²à¸„à¸²à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ", "à¹‚à¸›à¸£ {p} à¸¢à¸±à¸‡à¸¡à¸µà¹„à¸«à¸¡"]:
            questions.append({
                "id": f"prm_{qid:04d}",
                "category": "promotions",
                "question": t.format(p=promo),
                "expected_keywords": [promo.split()[0]],
                "should_not_contain": [],
                "difficulty": "medium",
                "generated": True
            })
            qid += 1
    
    return questions

def generate_clinic_info() -> List[Dict]:
    """à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸–à¸²à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸¥à¸´à¸™à¸´à¸"""
    questions = []
    qid = 9000
    
    templates = [
        "à¸„à¸¥à¸´à¸™à¸´à¸à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¹„à¸«à¸™", "à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆà¸„à¸¥à¸´à¸™à¸´à¸", "à¹€à¸›à¸´à¸”à¸—à¸³à¸à¸²à¸£à¸§à¸±à¸™à¹„à¸«à¸™",
        "à¹€à¸›à¸´à¸”à¸à¸µà¹ˆà¹‚à¸¡à¸‡", "à¸•à¸´à¸”à¸•à¹ˆà¸­à¸¢à¸±à¸‡à¹„à¸‡", "à¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£", "LINE à¸„à¸¥à¸´à¸™à¸´à¸",
        "à¸ˆà¸­à¸‡à¸„à¸´à¸§à¸¢à¸±à¸‡à¹„à¸‡", "à¸™à¸±à¸”à¸«à¸¡à¸²à¸¢à¸¢à¸±à¸‡à¹„à¸‡", "à¹„à¸›à¸„à¸¥à¸´à¸™à¸´à¸à¸¢à¸±à¸‡à¹„à¸‡"
    ]
    
    variations = ["", "à¸„à¸°", "à¸„à¸£à¸±à¸š", "à¸«à¸™à¹ˆà¸­à¸¢", "à¹„à¸”à¹‰à¹„à¸«à¸¡"]
    
    for template in templates:
        for var in variations:
            questions.append({
                "id": f"cli_{qid:04d}",
                "category": "clinic_info",
                "question": f"{template}{var}",
                "expected_keywords": ["à¸„à¸¥à¸´à¸™à¸´à¸"],
                "should_not_contain": [],
                "difficulty": "easy",
                "generated": True
            })
            qid += 1
    
    return questions

def generate_edge_cases() -> List[Dict]:
    """Edge cases"""
    questions = []
    qid = 10000
    
    cases = [
        ("à¸ªà¸§à¸±à¸ªà¸”à¸µ", ["à¸ªà¸§à¸±à¸ªà¸”à¸µ"], [], "easy"),
        ("à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°", ["à¸ªà¸§à¸±à¸ªà¸”à¸µ"], [], "easy"),
        ("à¸‚à¸­à¸šà¸„à¸¸à¸“", ["à¸‚à¸­à¸šà¸„à¸¸à¸“"], [], "easy"),
        ("à¸Šà¹ˆà¸§à¸¢à¸§à¸´à¸™à¸´à¸ˆà¸‰à¸±à¸¢à¹‚à¸£à¸„", ["à¸›à¸£à¸¶à¸à¸©à¸²"], ["à¸§à¸´à¸™à¸´à¸ˆà¸‰à¸±à¸¢"], "hard"),
        ("à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¹ƒà¸„à¸£", ["AI"], [], "easy"),
        ("à¸£à¸²à¸„à¸²à¸–à¸¹à¸à¸ªà¸¸à¸”", ["à¸£à¸²à¸„à¸²"], [], "medium"),
    ]
    
    for q, exp, forb, diff in cases:
        questions.append({
            "id": f"edg_{qid:04d}",
            "category": "edge_case",
            "question": q,
            "expected_keywords": exp,
            "should_not_contain": forb,
            "difficulty": diff,
            "generated": True
        })
        qid += 1
    
    return questions

def generate_large_dataset(target: int = 800) -> List[Dict]:
    """Generate large dataset"""
    print(f"ðŸ”„ Generating {target}+ test questions...")
    
    all_q = []
    all_q.extend(generate_basic_questions())
    print(f"  âœ… Basic: {len(all_q)}")
    
    comp = generate_comparison_questions()
    all_q.extend(comp)
    print(f"  âœ… Comparison: {len(comp)}")
    
    prob = generate_problem_questions()
    all_q.extend(prob)
    print(f"  âœ… Problems: {len(prob)}")
    
    bud = generate_budget_questions()
    all_q.extend(bud)
    print(f"  âœ… Budget: {len(bud)}")
    
    promo = generate_promotion_questions()
    all_q.extend(promo)
    print(f"  âœ… Promotions: {len(promo)}")
    
    clinic = generate_clinic_info()
    all_q.extend(clinic)
    print(f"  âœ… Clinic: {len(clinic)}")
    
    edge = generate_edge_cases()
    all_q.extend(edge)
    print(f"  âœ… Edge: {len(edge)}")
    
    random.shuffle(all_q)
    
    if len(all_q) > target:
        all_q = all_q[:target]
    
    print(f"\nâœ… Total Generated: {len(all_q)}")
    return all_q

def export_large_dataset(output_file: str = "data/test_dataset_large.json", target_size: int = 800):
    """Export dataset"""
    test_cases = generate_large_dataset(target_size)
    
    categories = {}
    difficulties = {}
    
    for tc in test_cases:
        cat = tc["category"]
        diff = tc["difficulty"]
        categories[cat] = categories.get(cat, 0) + 1
        difficulties[diff] = difficulties.get(diff, 0) + 1
    
    data = {
        "metadata": {
            "total_cases": len(test_cases),
            "target_size": target_size,
            "categories": categories,
            "difficulty_levels": difficulties,
            "generated": True
        },
        "test_cases": test_cases
    }
    
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"\nðŸ’¾ Saved to {output_file}")
    print("\n" + "="*60)
    print("ðŸ“Š Large Dataset Summary")
    print("="*60)
    print(f"Total Questions: {len(test_cases)}")
    print("\nBy Category:")
    for cat, count in sorted(categories.items()):
        print(f"  - {cat}: {count}")
    print("\nBy Difficulty:")
    for diff, count in sorted(difficulties.items()):
        print(f"  - {diff}: {count}")
    
    return output_path

if __name__ == "__main__":
    export_large_dataset(target_size=1000)
