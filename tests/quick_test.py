#!/usr/bin/env python3
"""
Quick Model Test - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏£‡πá‡∏ß‡πÜ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏ô‡∏≤‡∏ô
‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏Ñ‡πà‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞ category

Usage:
    python tests/quick_test.py
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# Add parent to path
sys.path.insert(0, str(Path(__file__).parent.parent))

load_dotenv()

# Quick test samples (2-3 per category)
QUICK_TEST_SAMPLES = [
    # Services & Pricing (2)
    {
        "question": "MTS PDRN ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏∞",
        "category": "services_pricing",
        "expected": ["MTS", "PDRN", "‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π‡∏ú‡∏¥‡∏ß"]
    },
    {
        "question": "MTS PDRN ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏∞",
        "category": "services_pricing",
        "expected": ["‡∏£‡∏≤‡∏Ñ‡∏≤", "‡∏ö‡∏≤‡∏ó"]
    },
    
    # Promotions (2)
    {
        "question": "‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏∞",
        "category": "promotions",
        "expected": ["‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô"]
    },
    {
        "question": "Meso Promotion 5 Times 999 ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£",
        "category": "promotions",
        "expected": ["Meso", "999", "5"]
    },
    
    # Clinic Info (2)
    {
        "question": "‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∞",
        "category": "clinic_info",
        "expected": ["‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà"]
    },
    {
        "question": "‡∏à‡∏≠‡∏á‡∏Ñ‡∏¥‡∏ß‡πÑ‡∏î‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏á",
        "category": "clinic_info",
        "expected": ["‡∏à‡∏≠‡∏á", "‡∏Ñ‡∏¥‡∏ß"]
    },
    
    # Complex (2)
    {
        "question": "‡∏ú‡∏¥‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏´‡πâ‡∏á‡∏°‡∏≤‡∏Å ‡∏°‡∏µ‡∏£‡∏¥‡πâ‡∏ß‡∏£‡∏≠‡∏¢ ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏î‡∏µ‡∏Ñ‡∏∞",
        "category": "complex",
        "expected": ["MTS", "PDRN", "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"]
    },
    {
        "question": "‡∏á‡∏ö 10,000 ‡∏ö‡∏≤‡∏ó ‡∏ó‡∏≥‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á",
        "category": "complex",
        "expected": ["‡∏£‡∏≤‡∏Ñ‡∏≤", "‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£"]
    },
    
    # Edge Cases (1)
    {
        "question": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞",
        "category": "edge_case",
        "expected": ["‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ"]
    },
]


def quick_test():
    """Run quick test"""
    print("="*60)
    print("üöÄ Quick Model Test")
    print("="*60)
    
    # Check API key
    if not os.getenv("OPENAI_API_KEY"):
        print("\n‚ùå OPENAI_API_KEY not found in .env")
        print("üí° Please add your OpenAI API key to .env file:")
        print("   OPENAI_API_KEY=sk-your-key-here")
        return
    
    # Import service
    try:
        from core.enhanced_ai_service import get_enhanced_ai_service
    except ImportError as e:
        print(f"\n‚ùå Import error: {e}")
        return
    
    # Initialize
    print("\nüì¶ Initializing AI Service...")
    try:
        service = get_enhanced_ai_service(use_rag=True, use_vision=False)
        print("‚úÖ Service initialized")
    except Exception as e:
        print(f"‚ùå Initialization error: {e}")
        return
    
    # Run tests
    print(f"\nüß™ Running {len(QUICK_TEST_SAMPLES)} quick tests...\n")
    
    passed = 0
    failed = 0
    
    for i, test in enumerate(QUICK_TEST_SAMPLES, 1):
        question = test["question"]
        category = test["category"]
        expected = test["expected"]
        
        print(f"[{i}/{len(QUICK_TEST_SAMPLES)}] {category}")
        print(f"Q: {question}")
        
        try:
            # Query
            result = service.chat(message=question, use_cache=False)
            response = result.get("response", "")
            source = result.get("source", "unknown")
            latency = result.get("latency_ms", 0)
            
            # Check keywords
            response_lower = response.lower()
            found = [kw for kw in expected if kw.lower() in response_lower]
            
            # Status
            if len(found) >= len(expected) * 0.5:  # 50% threshold
                status = "‚úÖ PASS"
                passed += 1
            else:
                status = "‚ùå FAIL"
                failed += 1
            
            print(f"A: {response[:150]}...")
            print(f"{status} | Source: {source} | Latency: {latency:.0f}ms")
            print(f"Keywords: {found}/{expected}")
            
        except Exception as e:
            print(f"‚ùå ERROR: {e}")
            failed += 1
        
        print("-" * 60)
    
    # Summary
    total = len(QUICK_TEST_SAMPLES)
    pass_rate = passed / total * 100
    
    print("\n" + "="*60)
    print("üìä Quick Test Summary")
    print("="*60)
    print(f"Total: {total}")
    print(f"‚úÖ Passed: {passed} ({pass_rate:.1f}%)")
    print(f"‚ùå Failed: {failed} ({100-pass_rate:.1f}%)")
    
    if pass_rate >= 80:
        print("\nüéâ Model performing well!")
    elif pass_rate >= 60:
        print("\n‚ö†Ô∏è  Model needs improvement")
    else:
        print("\n‚ùå Model needs major fixes")
    
    print("\nüí° Run full evaluation:")
    print("   python tests/evaluate_model.py")


if __name__ == "__main__":
    quick_test()
