"""
RAG Service for Seoulholic Clinic
‡πÉ‡∏ä‡πâ LlamaIndex + ChromaDB ‡πÄ‡∏û‡∏∑‡πà‡∏≠ query ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å
‡∏•‡∏î hallucination ‡∏•‡∏á 80% ‡πÇ‡∏î‡∏¢‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å vector DB ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
"""

from llama_index.core import VectorStoreIndex, Document, Settings, StorageContext
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from llama_index.vector_stores.chroma import ChromaVectorStore
import chromadb
import json
import os
from pathlib import Path
from typing import List, Dict, Optional
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SeoulholicRAG:
    """RAG System ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Seoulholic Clinic"""
    
    def __init__(self, chroma_path: str = "./chroma_db"):
        """
        Initialize RAG system
        
        Args:
            chroma_path: Path to ChromaDB storage
        """
        # Setup LlamaIndex
        Settings.embed_model = OpenAIEmbedding(
            model="text-embedding-3-small",  # ‡∏ñ‡∏π‡∏Å‡∏™‡∏∏‡∏î $0.00002/1K tokens
            api_key=os.getenv("OPENAI_API_KEY")
        )
        Settings.llm = OpenAI(
            model="gpt-4o-mini",  # ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ gpt-4o 60x, ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ 2x
            temperature=0.3,  # ‡∏ï‡πà‡∏≥ = ‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠, ‡∏™‡∏π‡∏á = creative
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # Setup ChromaDB
        self.chroma_client = chromadb.PersistentClient(path=chroma_path)
        self.collection = self.chroma_client.get_or_create_collection(
            name="seoulholic_knowledge",
            metadata={"hnsw:space": "cosine"}  # cosine similarity
        )
        
        # Initialize index
        self.index = None
        self._initialize_knowledge_base()
        
        logger.info(" RAG Service initialized successfully")
    
    def _initialize_knowledge_base(self):
        """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏Ç‡πâ‡∏≤ Vector DB"""
        documents = []
        
        # 1. ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå text ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å data/text/
        text_dir = Path("data/text")
        if text_dir.exists():
            for text_file in text_dir.glob("*.txt"):
                try:
                    with open(text_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if content.strip():  # ‡∏°‡∏µ content
                            documents.append(Document(
                                text=content,
                                metadata={
                                    "source": str(text_file),
                                    "type": "service_info",
                                    "filename": text_file.name
                                }
                            ))
                            logger.info(f"üìÑ Loaded: {text_file.name}")
                except Exception as e:
                    logger.error(f" Error loading {text_file}: {e}")
        
        # 2. ‡πÇ‡∏´‡∏•‡∏î Facebook promotions
        fb_promo_path = Path("data/fb_promotions.json")
        if fb_promo_path.exists():
            try:
                with open(fb_promo_path, 'r', encoding='utf-8') as f:
                    promotions = json.load(f)
                    for idx, promo in enumerate(promotions):
                        message = promo.get('message', '')
                        if message:
                            documents.append(Document(
                                text=f"‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô Facebook:\n{message}",
                                metadata={
                                    "source": "facebook",
                                    "type": "promotion",
                                    "post_id": promo.get('id', f'promo_{idx}'),
                                    "created_time": promo.get('created_time', '')
                                }
                            ))
                    logger.info(f"[DATA] Loaded {len(promotions)} Facebook promotions")
            except Exception as e:
                logger.error(f" Error loading Facebook promotions: {e}")
        
        # 3. ‡πÇ‡∏´‡∏•‡∏î FAQ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        faq_path = Path("data/faq.json")
        if faq_path.exists():
            try:
                with open(faq_path, 'r', encoding='utf-8') as f:
                    faqs = json.load(f)
                    for faq in faqs:
                        documents.append(Document(
                            text=f"Q: {faq['question']}\nA: {faq['answer']}",
                            metadata={
                                "source": "faq",
                                "type": "faq",
                                "category": faq.get('category', 'general')
                            }
                        ))
                    logger.info(f"‚ùì Loaded {len(faqs)} FAQs")
            except:
                pass  # ‡πÑ‡∏°‡πà‡∏°‡∏µ FAQ ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏£
        
        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store Index
        if documents:
            vector_store = ChromaVectorStore(chroma_collection=self.collection)
            storage_context = StorageContext.from_defaults(vector_store=vector_store)
            
            self.index = VectorStoreIndex.from_documents(
                documents,
                storage_context=storage_context,
                show_progress=True
            )
            logger.info(f" Indexed {len(documents)} documents into Chroma")
        else:
            logger.warning(" No documents found to index!")
    
    def query(
        self, 
        question: str, 
        similarity_top_k: int = 5,
        response_mode: str = "compact"
    ) -> Dict:
        """
        Query RAG system
        
        Args:
            question: ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
            similarity_top_k: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô documents ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏°‡∏≤ (default: 5)
            response_mode: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á response (compact/tree_summarize/simple_summarize)
        
        Returns:
            Dict with answer, sources, and confidence
        """
        if not self.index:
            return {
                "answer": "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ñ‡πà‡∏∞",
                "sources": [],
                "confidence": 0.0
            }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á query engine
        query_engine = self.index.as_query_engine(
            similarity_top_k=similarity_top_k,
            response_mode=response_mode
        )
        
        # Enhanced prompt ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Seoulholic
        enhanced_prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI assistant ‡∏Ç‡∏≠‡∏á Seoulholic Clinic 
        
‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
1. ‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏≠‡∏á
2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ ‡πÉ‡∏´‡πâ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡πâ‡∏ô‡∏∞‡∏Ñ‡∏∞"
3. ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÉ‡∏ä‡πâ "‡∏Ñ‡πà‡∏∞/‡∏Ñ‡∏∞"
4. ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏î‡πâ‡∏ß‡∏¢
5. ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤ ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ "‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô" ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: {question}"""
        
        try:
            # Query
            response = query_engine.query(enhanced_prompt)
            
            # Extract sources
            sources = []
            for node in response.source_nodes:
                sources.append({
                    "text": node.text[:200] + "...",  # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 200 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÅ‡∏£‡∏Å
                    "metadata": node.metadata,
                    "score": node.score  # similarity score
                })
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì confidence ‡∏à‡∏≤‡∏Å average similarity score
            avg_score = sum(s["score"] for s in sources) / len(sources) if sources else 0.0
            
            return {
                "answer": str(response),
                "sources": sources,
                "confidence": avg_score,
                "top_k": similarity_top_k
            }
            
        except Exception as e:
            logger.error(f" Query error: {e}")
            return {
                "answer": "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏∞",
                "sources": [],
                "confidence": 0.0,
                "error": str(e)
            }
    
    def add_document(self, text: str, metadata: Dict):
        """‡πÄ‡∏û‡∏¥‡πà‡∏° document ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤ vector DB (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö auto-update)"""
        if not self.index:
            logger.error("Index not initialized")
            return
        
        doc = Document(text=text, metadata=metadata)
        self.index.insert(doc)
        logger.info(f" Added new document: {metadata.get('source', 'unknown')}")
    
    def update_from_facebook(self, posts: List[Dict]):
        """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï RAG ‡∏à‡∏≤‡∏Å Facebook posts ‡πÉ‡∏´‡∏°‡πà"""
        for post in posts:
            message = post.get('message', '')
            if message:
                self.add_document(
                    text=f"‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô/‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:\n{message}",
                    metadata={
                        "source": "facebook_auto_update",
                        "type": "promotion",
                        "post_id": post.get('id'),
                        "created_time": post.get('created_time'),
                        "updated_at": post.get('updated_time')
                    }
                )
        logger.info(f" Updated {len(posts)} Facebook posts to RAG")


# Singleton instance
_rag_instance = None

def get_rag_service() -> SeoulholicRAG:
    """Get singleton RAG service instance"""
    global _rag_instance
    if _rag_instance is None:
        _rag_instance = SeoulholicRAG()
    return _rag_instance


if __name__ == "__main__":
    # Test RAG
    rag = get_rag_service()
    
    # Test queries
    test_questions = [
        "MTS PDRN ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏∞",
        "‡∏£‡∏≤‡∏Ñ‡∏≤ Skin Reset ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà",
        "‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏∞",
        "‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∞"
    ]
    
    for question in test_questions:
        print(f"\n{'='*60}")
        print(f"Q: {question}")
        result = rag.query(question)
        print(f"A: {result['answer']}")
        print(f"Confidence: {result['confidence']:.2f}")
        print(f"Sources: {len(result['sources'])} documents")
