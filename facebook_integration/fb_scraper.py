"""
Facebook Page Scraper Module
‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Facebook Page ‡∏Ç‡∏≠‡∏á Seoulholic Clinic ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Graph API
"""

import os
import json
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from pathlib import Path


class FacebookPageScraper:
    """Class ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Facebook Page"""
    
    def __init__(self, access_token: Optional[str] = None, page_id: Optional[str] = None):
        """
        Initialize Facebook Scraper
        
        Args:
            access_token: Facebook Access Token (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å ENV)
            page_id: Facebook Page ID (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å ENV)
        """
        self.access_token = access_token or os.getenv("FB_ACCESS_TOKEN", "")
        self.page_id = page_id or os.getenv("FB_PAGE_ID", "SeoulholicClinic")
        self.base_url = "https://graph.facebook.com/v18.0"
        
    def get_latest_posts(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        ‡∏î‡∏∂‡∏á‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Facebook Page
        
        Args:
            limit: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á (default: 10)
            
        Returns:
            List[Dict]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏û‡∏™‡∏ï‡πå
        """
        if not self.access_token:
            print("[WARNING] ‡πÑ‡∏°‡πà‡∏û‡∏ö FB_ACCESS_TOKEN - ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏´‡∏°‡∏î Demo")
            return self._get_demo_posts()
        
        try:
            # API endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡πÇ‡∏û‡∏™‡∏ï‡πå
            url = f"{self.base_url}/{self.page_id}/posts"
            
            params = {
                "access_token": self.access_token,
                "fields": "id,message,created_time,full_picture,permalink_url,attachments{media,url}",
                "limit": limit
            }
            
            response = requests.get(url, params=params)
            response.raise_for_status()
            
            data = response.json()
            posts = data.get("data", [])
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            formatted_posts = []
            for post in posts:
                formatted_posts.append({
                    "id": post.get("id", ""),
                    "message": post.get("message", ""),
                    "created_time": post.get("created_time", ""),
                    "image_url": post.get("full_picture", ""),
                    "post_url": post.get("permalink_url", ""),
                    "type": self._detect_post_type(post.get("message", ""))
                })
            
            return formatted_posts
            
        except Exception as e:
            print(f"[ERROR] Error fetching posts: {e}")
            return self._get_demo_posts()
    
    def get_promotions(self) -> List[Dict[str, Any]]:
        """
        ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô
        
        Returns:
            List[Dict]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô
        """
        posts = self.get_latest_posts(limit=20)
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô
        promotions = []
        promo_keywords = [
            "‡πÇ‡∏õ‡∏£", "promotion", "‡∏•‡∏î", "discount", "‡∏û‡∏¥‡πÄ‡∏®‡∏©", "special",
            "‡πÅ‡∏ñ‡∏°", "free", "‡∏ü‡∏£‡∏µ", "‡∏£‡∏≤‡∏Ñ‡∏≤", "price", "‡∏ö‡∏≤‡∏ó"
        ]
        
        for post in posts:
            message = post.get("message", "").lower()
            if any(keyword in message for keyword in promo_keywords):
                promotions.append(post)
        
        return promotions
    
    def save_to_file(self, posts: List[Dict[str, Any]], filename: str = "fb_posts.json"):
        """
        ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå JSON
        
        Args:
            posts: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏û‡∏™‡∏ï‡πå
            filename: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        """
        data_dir = Path(__file__).resolve().parents[1] / "data"
        data_dir.mkdir(exist_ok=True)
        
        filepath = data_dir / filename
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump({
                "updated_at": datetime.now().isoformat(),
                "posts": posts
            }, f, ensure_ascii=False, indent=2)
        
        print(f"[OK] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å {len(posts)} ‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå {filepath}")
    
    def load_from_file(self, filename: str = "fb_posts.json") -> Dict[str, Any]:
        """
        ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON
        
        Args:
            filename: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
            
        Returns:
            Dict: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏û‡∏£‡πâ‡∏≠‡∏° timestamp
        """
        data_dir = Path(__file__).resolve().parents[1] / "data"
        filepath = data_dir / filename
        
        if not filepath.exists():
            return {"updated_at": None, "posts": []}
        
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    
    def _detect_post_type(self, message: str) -> str:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÇ‡∏û‡∏™‡∏ï‡πå
        
        Args:
            message: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡πÇ‡∏û‡∏™‡∏ï‡πå
            
        Returns:
            str: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏û‡∏™‡∏ï‡πå
        """
        message_lower = message.lower()
        
        if any(word in message_lower for word in ["‡πÇ‡∏õ‡∏£", "promotion", "‡∏•‡∏î", "discount"]):
            return "promotion"
        elif any(word in message_lower for word in ["review", "‡∏£‡∏µ‡∏ß‡∏¥‡∏ß", "‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤"]):
            return "review"
        elif any(word in message_lower for word in ["‡∏õ‡∏¥‡∏î", "closed", "‡πÄ‡∏õ‡∏¥‡∏î", "open", "‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î"]):
            return "announcement"
        else:
            return "general"
    
    def _get_demo_posts(self) -> List[Dict[str, Any]]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î Demo
        
        Returns:
            List[Dict]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
        """
        return [
            {
                "id": "demo_1",
                "message": " ‡πÇ‡∏õ‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏© Sculptra ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏î‡πá‡∏Å 2 ‡∏Ç‡∏ß‡∏î 20cc ‡πÄ‡∏û‡∏µ‡∏¢‡∏á 35,900.- (‡∏à‡∏≤‡∏Å‡∏õ‡∏Å‡∏ï‡∏¥ 47,800.-) ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏û‡∏µ‡∏¢‡∏á 5 ‡∏ó‡πà‡∏≤‡∏ô‡πÅ‡∏£‡∏Å! ",
                "created_time": datetime.now().isoformat(),
                "image_url": "",
                "post_url": "https://www.facebook.com/SeoulholicClinic",
                "type": "promotion"
            },
            {
                "id": "demo_2",
                "message": "[NEW] ‡πÇ‡∏õ‡∏£‡∏ü‡∏¥‡∏•‡πÄ‡∏•‡∏≠‡∏£‡πå‡∏™‡∏∏‡∏î‡∏Ñ‡∏∏‡πâ‡∏°! CC ‡πÅ‡∏£‡∏Å 12,900.- | CC ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ 9,999.-/cc (15-31 ‡∏°.‡∏Ñ. 2569) ‡πÄ‡∏™‡∏£‡∏¥‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏™‡πà‡∏ß‡∏ô ‡∏Ñ‡∏≤‡∏á ‡∏Å‡∏£‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡πÅ‡∏Å‡πâ‡∏° ‡∏£‡∏¥‡∏°‡∏ù‡∏µ‡∏õ‡∏≤‡∏Å ‡πÉ‡∏ï‡πâ‡∏ï‡∏≤ ",
                "created_time": (datetime.now() - timedelta(days=1)).isoformat(),
                "image_url": "",
                "post_url": "https://www.facebook.com/SeoulholicClinic",
                "type": "promotion"
            },
            {
                "id": "demo_3",
                "message": "üéâ ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏ú‡∏¥‡∏ß Signature Skin Reset ‡∏ú‡∏¥‡∏ß‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å ‡∏´‡∏•‡∏∏‡∏°‡∏™‡∏¥‡∏ß‡∏î‡∏π‡∏ï‡∏∑‡πâ‡∏ô‡∏•‡∏á ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏ß‡πâ‡∏ß‡∏≤‡∏á‡πÉ‡∏à‡∏ô‡∏∞‡∏Ñ‡∏∞ üíï",
                "created_time": (datetime.now() - timedelta(days=2)).isoformat(),
                "image_url": "",
                "post_url": "https://www.facebook.com/SeoulholicClinic",
                "type": "review"
            }
        ]


def format_posts_for_chatbot(posts: List[Dict[str, Any]]) -> str:
    """
    ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏™‡πà‡πÉ‡∏ô System Prompt
    
    Args:
        posts: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏û‡∏™‡∏ï‡πå
        
    Returns:
        str: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÅ‡∏•‡πâ‡∏ß
    """
    if not posts:
        return ""
    
    formatted = "# ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Facebook (‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï: " + datetime.now().strftime("%d/%m/%Y %H:%M") + ")\n\n"
    
    for i, post in enumerate(posts[:5], 1):  # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 5 ‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        message = post.get("message", "")
        post_url = post.get("post_url", "")
        created_time = post.get("created_time", "")
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        try:
            dt = datetime.fromisoformat(created_time.replace("Z", "+00:00"))
            date_str = dt.strftime("%d/%m/%Y")
        except:
            date_str = "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"
        
        formatted += f"## ‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà {i} ({date_str})\n"
        formatted += f"{message}\n"
        if post_url:
            formatted += f"‡∏•‡∏¥‡∏á‡∏Å‡πå: {post_url}\n"
        formatted += "\n"
    
    return formatted


if __name__ == "__main__":
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
    print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö Facebook Scraper...\n")
    
    scraper = FacebookPageScraper()
    
    # ‡∏î‡∏∂‡∏á‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    print("üì• ‡∏î‡∏∂‡∏á‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î...")
    posts = scraper.get_latest_posts(limit=5)
    print(f"[OK] ‡∏û‡∏ö {len(posts)} ‡πÇ‡∏û‡∏™‡∏ï‡πå\n")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏û‡∏™‡∏ï‡πå
    for i, post in enumerate(posts, 1):
        print(f"--- ‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà {i} ---")
        print(f"Type: {post['type']}")
        print(f"Message: {post['message'][:100]}...")
        print()
    
    # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô
    print("\nüéÅ ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô...")
    promotions = scraper.get_promotions()
    print(f"[OK] ‡∏û‡∏ö {len(promotions)} ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô\n")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
    print("[SAVED] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå...")
    scraper.save_to_file(posts)
    scraper.save_to_file(promotions, "fb_promotions.json")
    
    # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö chatbot
    print("\nüìù ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Chatbot:")
    print(format_posts_for_chatbot(promotions))
